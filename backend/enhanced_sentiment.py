#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆèˆ†æƒ…åˆ†æç³»ç»Ÿ
- å¤šæ–°é—»æºæ•´åˆ
- æ·±åº¦æƒ…æ„Ÿåˆ†æ
- çƒ­ç‚¹è¿½è¸ª
- åŒ—å‘èµ„é‡‘ç›‘æ§
"""

import sys
import os
import time
import re
from typing import List, Dict, Any, Tuple
from datetime import datetime, timedelta

import pandas as pd

backend_dir = os.path.dirname(os.path.abspath(__file__))
if backend_dir not in sys.path:
    sys.path.insert(0, backend_dir)

import akshare as ak
from utils.tushare_client import pro


class EnhancedSentimentAnalyzer:
    """å¢å¼ºç‰ˆèˆ†æƒ…åˆ†æå™¨"""
    
    def __init__(self):
        # æƒ…æ„Ÿå…³é”®è¯åº“
        self.positive_keywords = [
            "æ¶¨", "ä¸Šæ¶¨", "å¤§æ¶¨", "æš´æ¶¨", "åˆ›æ–°é«˜", "çªç ´", "åˆ©å¥½", "è¶…é¢„æœŸ",
            "ç›ˆåˆ©", "ä¸šç»©å¤§å¢", "æ‰­äºä¸ºç›ˆ", "ç­¾çº¦", "ä¸­æ ‡", "æ”¶è´­", "å¹¶è´­",
            "æˆ˜ç•¥åˆä½œ", "æ”¿ç­–æ”¯æŒ", "è¡¥è´´", "å‡ç¨", "è¡Œä¸šæ™¯æ°”", "éœ€æ±‚æ—ºç››",
            "ä¾›ä¸åº”æ±‚", "æ¶¨ä»·", "æä»·", "æœºæ„ä¹°å…¥", "åŒ—å‘èµ„é‡‘", "å¢æŒ", "å›è´­"
        ]
        
        self.negative_keywords = [
            "è·Œ", "ä¸‹è·Œ", "å¤§è·Œ", "æš´è·Œ", "åˆ›æ–°ä½", "ç ´ä½", "åˆ©ç©º", "ä½äºé¢„æœŸ",
            "äºæŸ", "ä¸šç»©ä¸‹æ»‘", "å¤§å¹…äºæŸ", "è¿çº¦", "è¯‰è®¼", "è°ƒæŸ¥", "å¤„ç½š",
            "ç«‹æ¡ˆ", "å‡æŒ", "è§£ç¦", "è´¨æŠ¼", "å¹³ä»“", "é€€å¸‚é£é™©", "ç›‘ç®¡æ”¶ç´§",
            "è¡Œä¸šä¸æ™¯æ°”", "éœ€æ±‚ç–²è½¯", "ä¾›è¿‡äºæ±‚", "é™ä»·", "æœºæ„å–å‡º", "èµ„é‡‘æµå‡º"
        ]
        
        # çƒ­ç‚¹æ¿å—å…³é”®è¯
        self.sector_keywords = {
            "äººå·¥æ™ºèƒ½": ["AI", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "ChatGPT", "ç®—åŠ›", "èŠ¯ç‰‡", "GPU", "åŠå¯¼ä½“"],
            "æ–°èƒ½æº": ["æ–°èƒ½æº", "å…‰ä¼", "é£ç”µ", "å‚¨èƒ½", "åŠ¨åŠ›ç”µæ± ", "ç‰¹æ–¯æ‹‰", "æ¯”äºšè¿ª"],
            "æ±½è½¦": ["æ±½è½¦", "æ•´è½¦", "é›¶éƒ¨ä»¶", "è‡ªåŠ¨é©¾é©¶", "æ–°èƒ½æºè½¦"],
            "åŒ»è¯": ["åŒ»è¯", "åŒ»ç–—", "ç”Ÿç‰©", "ç–«è‹—", "åˆ›æ–°è¯", "CXO"],
            "æ¶ˆè´¹": ["æ¶ˆè´¹", "ç™½é…’", "é£Ÿå“", "é¥®æ–™", "é›¶å”®", "ç”µå•†"],
            "æˆ¿åœ°äº§": ["æˆ¿åœ°äº§", "åœ°äº§", "ä¿åˆ©", "ä¸‡ç§‘", "é‡‘åœ°"],
            "é‡‘è": ["é‡‘è", "é“¶è¡Œ", "è¯åˆ¸", "ä¿é™©", "åŸºé‡‘"],
            "æ•°å­—ç»æµ": ["æ•°å­—ç»æµ", "æ•°æ®è¦ç´ ", "ä¸œæ•°è¥¿ç®—", "ä¿¡åˆ›"],
            "å†›å·¥": ["å†›å·¥", "èˆªå¤©", "èˆªç©º", "é˜²åŠ¡", "å…µå™¨"],
            "å†œä¸š": ["å†œä¸š", "ç§ä¸š", "ç²®é£Ÿ", "ç”ŸçŒª", "å†œè¯"]
        }
    
    def clean_text(self, text: str) -> str:
        """æ¸…æ´—æ–‡æœ¬"""
        if not text:
            return ""
        text = str(text)
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        return text
    
    def analyze_sentiment_score(self, text: str) -> Tuple[int, List[str], List[str]]:
        """
        åˆ†æå•æ¡æ–°é—»çš„æƒ…æ„Ÿ
        è¿”å›: (æƒ…æ„Ÿåˆ†æ•°, æ­£é¢å…³é”®è¯, è´Ÿé¢å…³é”®è¯)
        """
        text = self.clean_text(text)
        if not text:
            return 50, [], []
        
        positive_hits = []
        negative_hits = []
        
        for kw in self.positive_keywords:
            if kw in text:
                positive_hits.append(kw)
        
        for kw in self.negative_keywords:
            if kw in text:
                negative_hits.append(kw)
        
        # è®¡ç®—æƒ…æ„Ÿåˆ†æ•°
        base_score = 50
        score = base_score + (len(positive_hits) * 8) - (len(negative_hits) * 10)
        score = max(0, min(100, score))
        
        return score, positive_hits, negative_hits
    
    def identify_sectors(self, text: str) -> List[str]:
        """è¯†åˆ«æ–°é—»æ¶‰åŠçš„æ¿å—"""
        text = self.clean_text(text)
        sectors = []
        
        for sector, keywords in self.sector_keywords.items():
            for kw in keywords:
                if kw in text:
                    sectors.append(sector)
                    break
        
        return list(set(sectors))
    
    def fetch_news_cailian(self, limit: int = 30) -> pd.DataFrame:
        """è·å–è´¢è”ç¤¾æ–°é—»"""
        news_list = []
        try:
            print("  æ­£åœ¨è·å–è´¢è”ç¤¾æ–°é—»...")
            df = ak.stock_info_global_cls()
            if df is not None and not df.empty:
                for _, row in df.head(limit).iterrows():
                    title = str(row.get("æ ‡é¢˜", ""))
                    content = str(row.get("å†…å®¹", ""))
                    pub_time = row.get("å‘å¸ƒæ—¶é—´", datetime.now())
                    
                    if not content and title:
                        content = title
                    
                    if content:
                        news_list.append({
                            "source": "è´¢è”ç¤¾",
                            "title": title,
                            "content": content,
                            "publish_time": pub_time
                        })
            print(f"    è´¢è”ç¤¾: è·å– {len(news_list)} æ¡")
        except Exception as e:
            print(f"    è´¢è”ç¤¾è·å–å¤±è´¥: {e}")
        
        return pd.DataFrame(news_list) if news_list else pd.DataFrame()
    
    def fetch_news_eastmoney(self, limit: int = 30) -> pd.DataFrame:
        """è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»"""
        news_list = []
        try:
            print("  æ­£åœ¨è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»...")
            df = ak.stock_news_em(symbol="000001")  # ç”¨å¹³å®‰é“¶è¡Œè·å–å¸‚åœºæ–°é—»
            if df is not None and not df.empty:
                for _, row in df.head(limit).iterrows():
                    title = str(row.get("title", ""))
                    content = str(row.get("content", ""))
                    pub_time = row.get("published time", datetime.now())
                    
                    if content:
                        news_list.append({
                            "source": "ä¸œæ–¹è´¢å¯Œ",
                            "title": title,
                            "content": content,
                            "publish_time": pub_time
                        })
            print(f"    ä¸œæ–¹è´¢å¯Œ: è·å– {len(news_list)} æ¡")
        except Exception as e:
            print(f"    ä¸œæ–¹è´¢å¯Œè·å–å¤±è´¥: {e}")
        
        return pd.DataFrame(news_list) if news_list else pd.DataFrame()
    
    def fetch_stock_news(self, code: str, name: str, limit: int = 15) -> List[Dict]:
        """è·å–ä¸ªè‚¡æ–°é—»"""
        news_list = []
        try:
            # å°è¯•ç”¨ akshare è·å–ä¸ªè‚¡æ–°é—»
            df = ak.stock_news_em(symbol=code)
            if df is not None and not df.empty:
                for _, row in df.head(limit).iterrows():
                    title = str(row.get("title", ""))
                    content = str(row.get("content", ""))
                    pub_time = row.get("published time", datetime.now())
                    
                    if content:
                        score, pos_kw, neg_kw = self.analyze_sentiment_score(content)
                        sectors = self.identify_sectors(content)
                        
                        news_list.append({
                            "title": title[:80] if title else content[:80],
                            "content": content[:200],
                            "sentiment_score": score,
                            "positive_keywords": pos_kw[:3],
                            "negative_keywords": neg_kw[:3],
                            "sectors": sectors,
                            "publish_time": pub_time
                        })
        except Exception as e:
            pass
        
        return news_list
    
    def fetch_northbound_flow(self) -> Dict[str, Any]:
        """è·å–åŒ—å‘èµ„é‡‘æ•°æ®"""
        flow_info = {
            "northbound_net_inflow": None,
            "sh_connect_inflow": None,
            "sz_connect_inflow": None,
            "trend": "æœªçŸ¥"
        }
        
        try:
            print("  æ­£åœ¨è·å–åŒ—å‘èµ„é‡‘æ•°æ®...")
            df = ak.stock_em_hsgt_north_net_flow_in()
            if df is not None and not df.empty:
                latest = df.iloc[0]
                flow_info["northbound_net_inflow"] = latest.get("å‡€ä¹°å…¥é¢", None)
                flow_info["sh_connect_inflow"] = latest.get("æ²ªè‚¡é€šå‡€ä¹°å…¥", None)
                flow_info["sz_connect_inflow"] = latest.get("æ·±è‚¡é€šå‡€ä¹°å…¥", None)
                
                # åˆ¤æ–­è¶‹åŠ¿
                if flow_info["northbound_net_inflow"] is not None:
                    inflow = float(flow_info["northbound_net_inflow"])
                    if inflow > 50:
                        flow_info["trend"] = "å¤§å¹…æµå…¥ ğŸ“ˆ"
                    elif inflow > 0:
                        flow_info["trend"] = "å°å¹…æµå…¥ ğŸ“Š"
                    elif inflow > -50:
                        flow_info["trend"] = "å°å¹…æµå‡º ğŸ“‰"
                    else:
                        flow_info["trend"] = "å¤§å¹…æµå‡º âš ï¸"
            
            print(f"    åŒ—å‘èµ„é‡‘: {flow_info['trend']}")
        except Exception as e:
            print(f"    åŒ—å‘èµ„é‡‘è·å–å¤±è´¥: {e}")
        
        return flow_info
    
    def fetch_hot_sectors(self) -> List[Dict]:
        """è·å–çƒ­é—¨æ¿å—æ¶¨å¹…æ¦œ"""
        sectors = []
        try:
            print("  æ­£åœ¨è·å–çƒ­é—¨æ¿å—...")
            df = ak.stock_board_industry_name_em()
            if df is not None and not df.empty:
                for _, row in df.head(10).iterrows():
                    name = row.get("æ¿å—åç§°", "")
                    change = row.get("æ¶¨è·Œå¹…", 0)
                    if name:
                        sectors.append({
                            "name": name,
                            "change_pct": float(change) if change else 0
                        })
            print(f"    çƒ­é—¨æ¿å—: è·å– {len(sectors)} ä¸ª")
        except Exception as e:
            print(f"    çƒ­é—¨æ¿å—è·å–å¤±è´¥: {e}")
        
        return sectors
    
    def analyze_market_sentiment(self, news_df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æå¸‚åœºæ•´ä½“æƒ…ç»ª"""
        if news_df.empty:
            return {
                "overall_sentiment_score": 50,
                "sentiment_label": "ä¸­æ€§",
                "positive_ratio": 0.5,
                "negative_ratio": 0.5,
                "hot_sectors_mentioned": []
            }
        
        all_scores = []
        all_sectors = []
        positive_count = 0
        negative_count = 0
        
        for _, row in news_df.iterrows():
            content = str(row.get("content", ""))
            score, _, _ = self.analyze_sentiment_score(content)
            all_scores.append(score)
            
            sectors = self.identify_sectors(content)
            all_sectors.extend(sectors)
            
            if score > 55:
                positive_count += 1
            elif score < 45:
                negative_count += 1
        
        avg_score = sum(all_scores) / len(all_scores) if all_scores else 50
        
        # ç¡®å®šæƒ…ç»ªæ ‡ç­¾
        if avg_score >= 65:
            label = "ä¹è§‚ ğŸ“ˆ"
        elif avg_score >= 55:
            label = "åå¤š ğŸ“Š"
        elif avg_score >= 45:
            label = "ä¸­æ€§ â–"
        elif avg_score >= 35:
            label = "åç©º ğŸ“‰"
        else:
            label = "æ‚²è§‚ âš ï¸"
        
        # ç»Ÿè®¡çƒ­é—¨æ¿å—
        sector_counts = {}
        for sector in all_sectors:
            sector_counts[sector] = sector_counts.get(sector, 0) + 1
        
        hot_sectors = sorted(sector_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        total = positive_count + negative_count or 1
        
        return {
            "overall_sentiment_score": round(avg_score, 1),
            "sentiment_label": label,
            "positive_ratio": round(positive_count / total, 2),
            "negative_ratio": round(negative_count / total, 2),
            "hot_sectors_mentioned": [s[0] for s in hot_sectors]
        }
    
    def analyze_stock_sentiment(self, code: str, name: str) -> Dict[str, Any]:
        """åˆ†æä¸ªè‚¡èˆ†æƒ…"""
        news_list = self.fetch_stock_news(code, name)
        
        if not news_list:
            return {
                "code": code,
                "name": name,
                "sentiment_score": 50,
                "news_count": 0,
                "recent_news": [],
                "related_sectors": []
            }
        
        scores = [n["sentiment_score"] for n in news_list]
        avg_score = sum(scores) / len(scores) if scores else 50
        
        all_sectors = []
        for news in news_list:
            all_sectors.extend(news["sectors"])
        
        return {
            "code": code,
            "name": name,
            "sentiment_score": round(avg_score, 1),
            "news_count": len(news_list),
            "recent_news": news_list[:5],
            "related_sectors": list(set(all_sectors))[:3]
        }


def main():
    print("=" * 80)
    print("                å¢å¼ºç‰ˆèˆ†æƒ…åˆ†æç³»ç»Ÿ")
    print("=" * 80)
    
    analyzer = EnhancedSentimentAnalyzer()
    t_total_start = time.perf_counter()
    
    # 1. è·å–å¤šæºæ–°é—»
    print("\n[1/5] è·å–å¸‚åœºæ–°é—»...")
    df_cailian = analyzer.fetch_news_cailian(limit=30)
    df_eastmoney = analyzer.fetch_news_eastmoney(limit=20)
    
    all_news = []
    if not df_cailian.empty:
        all_news.append(df_cailian)
    if not df_eastmoney.empty:
        all_news.append(df_eastmoney)
    
    df_all_news = pd.concat(all_news, axis=0, ignore_index=True) if all_news else pd.DataFrame()
    print(f"    å…±è·å– {len(df_all_news)} æ¡æ–°é—»")
    
    # 2. è·å–åŒ—å‘èµ„é‡‘
    print("\n[2/5] è·å–èµ„é‡‘æµå‘...")
    northbound = analyzer.fetch_northbound_flow()
    
    # 3. è·å–çƒ­é—¨æ¿å—
    print("\n[3/5] è·å–çƒ­é—¨æ¿å—...")
    hot_sectors = analyzer.fetch_hot_sectors()
    
    # 4. åˆ†æå¸‚åœºæƒ…ç»ª
    print("\n[4/5] åˆ†æå¸‚åœºæƒ…ç»ª...")
    market_sentiment = analyzer.analyze_market_sentiment(df_all_news)
    
    # 5. è¾“å‡ºç»“æœ
    print("\n" + "=" * 80)
    print("                     èˆ†æƒ…åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    print(f"\nğŸ“Š å¸‚åœºæƒ…ç»ªæ¦‚è§ˆ:")
    print(f"   æ•´ä½“æƒ…ç»ª: {market_sentiment['sentiment_label']}")
    print(f"   æƒ…ç»ªåˆ†æ•°: {market_sentiment['overall_sentiment_score']}/100")
    print(f"   æ­£é¢æ–°é—»å æ¯”: {int(market_sentiment['positive_ratio'] * 100)}%")
    print(f"   è´Ÿé¢æ–°é—»å æ¯”: {int(market_sentiment['negative_ratio'] * 100)}%")
    
    print(f"\nğŸ’µ åŒ—å‘èµ„é‡‘åŠ¨å‘:")
    print(f"   è¶‹åŠ¿: {northbound['trend']}")
    if northbound['northbound_net_inflow'] is not None:
        print(f"   å‡€ä¹°å…¥: {northbound['northbound_net_inflow']} äº¿")
        if northbound['sh_connect_inflow'] is not None:
            print(f"   æ²ªè‚¡é€š: {northbound['sh_connect_inflow']} äº¿")
        if northbound['sz_connect_inflow'] is not None:
            print(f"   æ·±è‚¡é€š: {northbound['sz_connect_inflow']} äº¿")
    
    print(f"\nğŸ”¥ çƒ­é—¨æ¿å—æ¶¨å¹…æ¦œ:")
    if hot_sectors:
        for i, sector in enumerate(hot_sectors[:8], 1):
            change = sector['change_pct']
            marker = "ğŸ“ˆ" if change > 0 else "ğŸ“‰" if change < 0 else "â–"
            print(f"   {i}. {sector['name']}: {change:+.2f}% {marker}")
    
    print(f"\nğŸ“° æ–°é—»ä¸­æåŠçš„çƒ­é—¨æ¿å—:")
    if market_sentiment['hot_sectors_mentioned']:
        print(f"   {', '.join(market_sentiment['hot_sectors_mentioned'])}")
    
    if not df_all_news.empty:
        print(f"\nğŸ“‹ æœ€æ–°é‡è¦æ–°é—» (æƒ…æ„Ÿåˆ†æ):")
        print("-" * 80)
        
        recent_news = df_all_news.head(10)
        for i, (_, row) in enumerate(recent_news.iterrows(), 1):
            content = str(row.get("content", ""))
            score, pos_kw, neg_kw = analyzer.analyze_sentiment_score(content)
            
            sentiment_marker = "ğŸ˜Š" if score >= 60 else "ğŸ˜" if score >= 40 else "ğŸ˜Ÿ"
            
            title = str(row.get("title", ""))[:50] or content[:50]
            source = row.get("source", "æœªçŸ¥")
            
            kw_str = ""
            if pos_kw:
                kw_str += f" [+:{','.join(pos_kw[:2])}]"
            if neg_kw:
                kw_str += f" [-:{','.join(neg_kw[:2])}]"
            
            print(f"{i}. [{source}] {title}... {sentiment_marker} (æƒ…æ„Ÿåˆ†:{score}){kw_str}")
    
    print("\n" + "=" * 80)
    print(f"â±ï¸  æ€»è€—æ—¶: {time.perf_counter() - t_total_start:.2f}s")
    print("=" * 80)


if __name__ == "__main__":
    main()
