import akshare as ak
import efinance as ef
import pandas as pd
import numpy as np
import time
import datetime
import traceback

# --- Helper Functions ---
_ERROR_COUNT = 0
_ERROR_TRACE_PRINTED = 0
_MAX_TRACEBACKS = 3

def _log_error(where: str, e: Exception):
    global _ERROR_COUNT, _ERROR_TRACE_PRINTED
    _ERROR_COUNT += 1
    print(f"âŒ ERROR[{_ERROR_COUNT}] {where}: {type(e).__name__}: {e}")
    if _ERROR_TRACE_PRINTED < _MAX_TRACEBACKS:
        print(traceback.format_exc())
        _ERROR_TRACE_PRINTED += 1

def normalize(series):
    if series.empty: return series
    min_val = series.min()
    max_val = series.max()
    if max_val == min_val: return pd.Series([1.0]*len(series), index=series.index)
    return (series - min_val) / (max_val - min_val)

def get_rpp(close, high_60, low_60):
    if high_60 == low_60: return 0.5
    return (close - low_60) / (high_60 - low_60)

def _safe_vwap(amount, volume, current_price):
    """
    è‡ªé€‚åº”è®¡ç®— VWAPï¼Œè‡ªåŠ¨ä¿®æ­£ 'æ‰‹' vs 'è‚¡' çš„å•ä½é—®é¢˜
    """
    if volume == 0: return current_price
    
    # å°è¯•1: å‡è®¾å•ä½æ˜¯è‚¡
    raw_vwap = amount / volume
    
    # æ£€æŸ¥æ•°é‡çº§å·®å¼‚
    if current_price > 0:
        ratio = raw_vwap / current_price
        if 80 < ratio < 120: # åå·®çº¦100å€ï¼Œè¯´æ˜ Volume æ˜¯æ‰‹ (Amountæ˜¯å…ƒ, Volæ˜¯æ‰‹) -> éœ€é™¤ä»¥100
            return raw_vwap / 100.0
        elif 0.8 < ratio < 1.2: # åå·®ä¸å¤§ï¼Œè¯´æ˜ Volume æ˜¯è‚¡
            return raw_vwap
            
    # å…œåº•ï¼šå¦‚æœæ— æ³•åˆ¤æ–­ï¼Œå‡è®¾æ˜¯æ‰‹ï¼ˆAè‚¡ spot æ¥å£é€šå¸¸è¿”å›æ‰‹ï¼‰
    # ä½†ä¸ºäº†ä¿é™©ï¼Œè¿˜æ˜¯è¿”å›ä¿®æ­£åçš„
    return raw_vwap / 100.0 if raw_vwap > current_price * 50 else raw_vwap

def _chunked(items, size: int):
    if not items:
        return
    for i in range(0, len(items), size):
        yield items[i : i + size]

def _fetch_latest_quotes_once(codes):
    df = ef.stock.get_latest_quote(codes)
    if df is None or df.empty:
        return pd.DataFrame()
    df = df.copy()
    df["ä»£ç "] = df["ä»£ç "].astype(str).str.zfill(6)
    for col in ["æœ€æ–°ä»·", "ä»Šå¼€", "æ˜¨æ—¥æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æ¶¨è·Œå¹…", "æ¢æ‰‹ç‡", "é‡æ¯”", "æˆäº¤é‡", "æˆäº¤é¢"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    return df

def _fetch_latest_quotes(codes):
    if not codes:
        return pd.DataFrame()
    out = []
    stack = [codes]
    while stack:
        chunk = stack.pop()
        try:
            out.append(_fetch_latest_quotes_once(chunk))
            time.sleep(0.05)
        except Exception as e:
            if len(chunk) <= 10:
                _log_error(f"ef.stock.get_latest_quote({len(chunk)})", e)
                continue
            mid = len(chunk) // 2
            stack.append(chunk[:mid])
            stack.append(chunk[mid:])
            time.sleep(0.2)
    if not out:
        return pd.DataFrame()
    df = pd.concat(out, ignore_index=True)
    df = df.dropna(subset=["ä»£ç "]).drop_duplicates(subset=["ä»£ç "], keep="last")
    return df

def _fetch_base_info_once(codes):
    df = ef.stock.get_base_info(codes)
    if df is None or (hasattr(df, "empty") and df.empty):
        return pd.DataFrame()
    if isinstance(df, pd.Series):
        df = df.to_frame().T
    df = df.copy()
    if "è‚¡ç¥¨ä»£ç " in df.columns:
        df["è‚¡ç¥¨ä»£ç "] = df["è‚¡ç¥¨ä»£ç "].astype(str).str.zfill(6)
    return df

def _fetch_base_info(codes):
    if not codes:
        return pd.DataFrame()
    out = []
    for chunk in _chunked(codes, 80):
        try:
            out.append(_fetch_base_info_once(chunk))
            time.sleep(0.05)
        except Exception as e:
            _log_error(f"ef.stock.get_base_info({len(chunk)})", e)
            time.sleep(0.2)
            continue
    if not out:
        return pd.DataFrame()
    df = pd.concat(out, ignore_index=True)
    if "è‚¡ç¥¨ä»£ç " in df.columns:
        df = df.dropna(subset=["è‚¡ç¥¨ä»£ç "]).drop_duplicates(subset=["è‚¡ç¥¨ä»£ç "], keep="last")
    return df

def _fetch_quote_history_once(codes):
    hist_dict = ef.stock.get_quote_history(codes)
    if not hist_dict:
        return {}
    return hist_dict

def _fetch_quote_history(codes):
    if not codes:
        return {}
    out = {}
    for chunk in _chunked(codes, 30):
        try:
            part = _fetch_quote_history_once(chunk)
            out.update(part)
            time.sleep(0.05)
        except Exception as e:
            _log_error(f"ef.stock.get_quote_history({len(chunk)})", e)
            time.sleep(0.2)
            continue
    return out

def fetch_stock_data(code, name, sector, hist: pd.DataFrame = None):
    """
    Worker function to fetch data for a single stock.
    Returns dict or None.
    """
    try:
        # 1. Get Daily Data (for Trend & RPP)
        if hist is None:
            hist_dict = ef.stock.get_quote_history([code])
            if not hist_dict or code not in hist_dict:
                return None
            hist = hist_dict[code]

        if hist is None or hist.empty or len(hist) < 60: return None
        
        # efinance columns: è‚¡ç¥¨åç§°, è‚¡ç¥¨ä»£ç , æ—¥æœŸ, å¼€ç›˜, æ”¶ç›˜, æœ€é«˜, æœ€ä½, æˆäº¤é‡, æˆäº¤é¢...
        # Map to expected columns
        last_row = hist.iloc[-1]
        close = float(last_row['æ”¶ç›˜'])
        
        # RPP Calculation
        window_60 = hist.tail(60)
        high_60 = window_60['æœ€é«˜'].max()
        low_60 = window_60['æœ€ä½'].min()
        rpp = get_rpp(close, high_60, low_60)
        
        # Trend: Price > MA20
        ma20 = window_60['æ”¶ç›˜'].tail(20).mean()
        
        return {
            "code": code,
            "name": name,
            "sector": sector,
            "close": close,
            "rpp": rpp,
            "ma20": ma20,
            "vol_prev": float(last_row['æˆäº¤é‡'])
        }
    except Exception as e:
        _log_error(f"fetch_stock_data({code})", e)
        return None

# --- Main Logic ---

print("ğŸ”¥ å¯åŠ¨ V2.0 æ¿å—èµ„é‡‘é€‰è‚¡å¼•æ“ (å•çº¿ç¨‹å®‰å…¨ç‰ˆ - efinanceåŠ å¼º)...")
start_time = time.time()

spot_df = pd.DataFrame()
try:
    universe = ak.stock_info_a_code_name()
    if universe is not None and not universe.empty:
        universe = universe.rename(columns={"code": "ä»£ç ", "name": "åç§°"})
        universe["ä»£ç "] = universe["ä»£ç "].astype(str).str.zfill(6)
        universe = universe[~universe["åç§°"].astype(str).str.contains("ST|é€€", na=False)]
        universe_codes = universe["ä»£ç "].tolist()
    else:
        universe_codes = []
except Exception as e:
    _log_error("ak.stock_info_a_code_name()", e)
    universe_codes = []

if universe_codes:
    print(f"ğŸ“¡ æ‹‰å–å…¨å¸‚åœºå®æ—¶å¿«ç…§ (via efinance.get_latest_quote, åˆ†æ‰¹)...")
    try:
        for chunk in _chunked(universe_codes, 150):
            try:
                part = _fetch_latest_quotes_once(chunk)
                if not part.empty:
                    spot_df = pd.concat([spot_df, part], ignore_index=True)
                time.sleep(0.05)
            except Exception as e:
                _log_error(f"ef.stock.get_latest_quote({len(chunk)})", e)
                time.sleep(0.2)
                continue
        if not spot_df.empty:
            spot_df = spot_df.dropna(subset=["ä»£ç "]).drop_duplicates(subset=["ä»£ç "], keep="last")
    except Exception as e:
        _log_error("build_spot_df()", e)
        spot_df = pd.DataFrame()

if spot_df.empty:
    df = pd.DataFrame([{"ä»£ç ": "-", "åç§°": "-", "ç‚¹è¯„": "å®æ—¶è¡Œæƒ…è·å–å¤±è´¥ï¼Œé€šå¸¸æ˜¯æ•°æ®æºè¿æ¥è¢«ä¸­æ–­"}])
    print(f"è€—æ—¶: {time.time() - start_time:.2f}s")
    if _ERROR_COUNT > 0:
        print(f"â— æœ¬æ¬¡è¿è¡Œæ•è·å¼‚å¸¸æ¬¡æ•°: {_ERROR_COUNT}")
    raise SystemExit(0)

scan_pool = spot_df.copy()
if "æˆäº¤é¢" in scan_pool.columns:
    scan_pool = scan_pool[scan_pool["æˆäº¤é¢"].fillna(0) > 0]
scan_pool = scan_pool.sort_values(by="æˆäº¤é¢", ascending=False).head(800)

base_info = _fetch_base_info(scan_pool["ä»£ç "].astype(str).tolist())
if not base_info.empty and "è‚¡ç¥¨ä»£ç " in base_info.columns:
    base_info = base_info.rename(columns={"è‚¡ç¥¨ä»£ç ": "ä»£ç ", "è‚¡ç¥¨åç§°": "åç§°", "æ‰€å¤„è¡Œä¸š": "æ¿å—"})
    scan_pool = scan_pool.merge(base_info[["ä»£ç ", "æ¿å—"]], on="ä»£ç ", how="left")
else:
    scan_pool["æ¿å—"] = ""

sector_list = (
    scan_pool.dropna(subset=["æ¿å—"])
    .groupby("æ¿å—")["æˆäº¤é¢"]
    .sum()
    .sort_values(ascending=False)
    .head(8)
    .index.tolist()
)
sector_list = [s for s in sector_list if isinstance(s, str) and s.strip()]
print(f"ğŸ¯ é”å®šçƒ­é—¨æ¿å—: {sector_list}")

candidates = []
if sector_list:
    cand_df = scan_pool[scan_pool["æ¿å—"].isin(sector_list)].copy()
else:
    cand_df = scan_pool.copy()
    cand_df["æ¿å—"] = "å…¨å¸‚åœº"

cand_df = cand_df.sort_values(by="æˆäº¤é¢", ascending=False).head(300)
for _, row in cand_df.iterrows():
    candidates.append(
        {
            "code": str(row["ä»£ç "]).zfill(6),
            "name": row.get("åç§°", ""),
            "sector": row.get("æ¿å—", "") or "å…¨å¸‚åœº",
        }
    )

print(f"ğŸ” åˆå§‹å€™é€‰æ± : {len(candidates)} åªè‚¡ç¥¨")

# 3. é¡ºåºè·å–æ•°æ® (Sequential Fetching)
# æ”¹ä¸ºå•çº¿ç¨‹ + å»¶æ—¶ï¼Œé˜²æ­¢å°IP
analyzed_stocks = []

if candidates:
    codes = [c["code"] for c in candidates]
    hist_map = _fetch_quote_history(codes)
    total_tasks = len(candidates)
    for i, c in enumerate(candidates):
        hist = hist_map.get(c["code"])
        res = fetch_stock_data(c["code"], c["name"], c["sector"], hist=hist)
        if res:
            analyzed_stocks.append(res)
        if i % 10 == 0:
            print(f"  è¿›åº¦: {i}/{total_tasks}...", end="\r")
        time.sleep(0.02)

print(f"\nâœ… æ•°æ®è·å–å®Œæˆï¼Œæœ‰æ•ˆè‚¡ç¥¨: {len(analyzed_stocks)}")

# 4. å®æ—¶è¡Œæƒ…æ ¡éªŒ (The Filter)
final_list = []
if not spot_df.empty and analyzed_stocks:
    # è½¬ä¸ºå­—å…¸åŠ é€ŸæŸ¥æ‰¾
    spot_map = spot_df.set_index('ä»£ç ').to_dict('index')
    
    for stock in analyzed_stocks:
        code = stock['code']
        if code not in spot_map: continue
        
        real = spot_map[code]
        
        # --- æ ¸å¿ƒè¿‡æ»¤é€»è¾‘ V2.0 ---
        
        try:
            current_price = float(real.get('æœ€æ–°ä»·', 0) or 0)
            open_price = float(real.get('ä»Šå¼€', 0) or 0)
            prev_close = float(real.get('æ˜¨æ—¥æ”¶ç›˜', 0) or real.get('æ˜¨æ”¶', 0) or 0)
            high_price = float(real.get('æœ€é«˜', 0) or 0)
            volume = float(real.get('æˆäº¤é‡', 0) or 0)
            amount = float(real.get('æˆäº¤é¢', 0) or 0)
            turnover = float(real.get('æ¢æ‰‹ç‡', 0) or 0)
            lb = float(real.get('é‡æ¯”', 0) or 0)
        except Exception as e:
            _log_error(f"parse_spot_row({code})", e)
            continue
            
        if current_price == 0: continue
        
        # 1. ç›¸å¯¹ä½ç½® RPP < 0.4 (ä½ä½)
        if stock['rpp'] >= 0.4: continue
        
        # 2. è¶‹åŠ¿æ”¯æ’‘ (ä»·æ ¼ > MA20)
        # if current_price < stock['ma20']: continue 
        
        # 3. å®æ—¶å¼ºåº¦ (Price > Open) -> æ‹’ç»å‡é˜´çº¿
        if current_price <= open_price: continue
        
        # 4. èµ„é‡‘å®é”¤ (Price > VWAP)
        # ä½¿ç”¨è‡ªé€‚åº” VWAP è®¡ç®—ï¼Œé˜²æ­¢å•ä½é™·é˜±
        if volume > 0:
            vwap = _safe_vwap(amount, volume, current_price)
            if current_price < vwap: continue
            
            # V2.1 ä¼˜åŒ–ï¼šä¹–ç¦»ç‡é™åˆ¶ < 1.5%
            # é˜²æ­¢è¿½é«˜æ¥ç›˜
            vwap_dev = (current_price - vwap) / vwap
            if vwap_dev > 0.015: continue
            
        # 5. é‡èƒ½ç¡®è®¤ (é‡æ¯” > 1.2 æˆ– æ¢æ‰‹ > 1%)
        if lb < 1.2: continue
        
        # 6. é£æ§ï¼šæ‹’ç»æ¶¨åœ (Limit Up)
        if current_price >= prev_close * 1.095: continue
        
        # 7. æ¶¨å¹…åŒºé—´ (1% < Chg < 6%)
        chg_pct = (current_price - prev_close) / prev_close * 100
        if chg_pct < 1.0 or chg_pct > 6.0: continue
        
        # --- è¯„åˆ†ç³»ç»Ÿ ---
        # ä½ä½åˆ† (30) + èµ„é‡‘åˆ† (40) + å¼ºåº¦åˆ† (30)
        score_pos = (1 - stock['rpp']) * 30
        score_fund = min(lb / 3.0, 1.0) * 40
        score_mom = min(chg_pct / 5.0, 1.0) * 30
        
        total_score = score_pos + score_fund + score_mom
        
        stock['æœ€æ–°ä»·'] = current_price
        stock['æ¶¨è·Œå¹…'] = chg_pct
        stock['é‡æ¯”'] = lb
        stock['VWAP'] = round(vwap, 2)
        stock['è¯„åˆ†'] = int(total_score)
        
        # ç‚¹è¯„ç”Ÿæˆ
        comments = []
        if stock['rpp'] < 0.1: comments.append("æä½ä½")
        elif stock['rpp'] < 0.3: comments.append("ç›¸å¯¹åº•éƒ¨")
        
        if current_price > vwap * 1.01: comments.append("ç«™ç¨³å‡ä»·")
        if lb > 2.0: comments.append(f"æ”¾é‡{lb}å€")
        
        stock['ç‚¹è¯„'] = ",".join(comments)
        
        final_list.append(stock)

# 5. è¾“å‡ºç»“æœ
df = pd.DataFrame(final_list)
if not df.empty:
    df = df.sort_values(by="è¯„åˆ†", ascending=False).head(30)
    # æ ¼å¼åŒ–è¾“å‡º
    out_cols = ['code', 'name', 'sector', 'æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'é‡æ¯”', 'rpp', 'è¯„åˆ†', 'ç‚¹è¯„']
    df = df[out_cols]
    df.columns = ['ä»£ç ', 'åç§°', 'æ¿å—', 'æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'é‡æ¯”', 'RPPä½ç½®', 'ç»¼åˆè¯„åˆ†', 'ç‚¹è¯„']
    
    print("\nğŸ† æœ€ç»ˆç²¾é€‰ (Top 30):")
    # print(df.to_string()) 

# å¿…é¡»èµ‹å€¼ç»™ df å˜é‡ä¾›ç³»ç»Ÿè¯»å–
df = df if not df.empty else pd.DataFrame(columns=['ä»£ç ', 'åç§°', 'ç‚¹è¯„'])
print(f"è€—æ—¶: {time.time() - start_time:.2f}s")
if _ERROR_COUNT > 0:
    print(f"â— æœ¬æ¬¡è¿è¡Œæ•è·å¼‚å¸¸æ¬¡æ•°: {_ERROR_COUNT}")
