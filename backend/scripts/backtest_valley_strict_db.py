import argparse
import contextlib
import datetime as _datetime
import io
import os
import random
import sqlite3
import sys
import time
import types
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

import akshare as real_ak
import numpy as np
import pandas as pd


def _normalize_symbol(code: str) -> str:
    s = "" if code is None else str(code).strip()
    if s.startswith(("sh", "sz", "bj")) and len(s) >= 8:
        return s[2:]
    return s


def _pick_universe(sample_size: int, seed: int):
    n = int(sample_size)
    if n <= 0:
        return {}
    random.seed(int(seed))

    spot = None
    for _ in range(3):
        try:
            spot = real_ak.stock_zh_a_spot_em()
            if spot is not None and not spot.empty:
                break
        except Exception:
            spot = None
        time.sleep(0.7)

    if spot is not None and not spot.empty:
        spot = spot.copy()
        spot = spot[~spot["åç§°"].str.contains("ST|é€€", na=False)]
        spot["æµé€šå¸‚å€¼"] = pd.to_numeric(spot["æµé€šå¸‚å€¼"], errors="coerce")
        spot = spot.dropna(subset=["ä»£ç ", "åç§°", "æµé€šå¸‚å€¼"])
        if not spot.empty:
            spot["ä»£ç "] = spot["ä»£ç "].map(_normalize_symbol)
            spot = spot[spot["ä»£ç "].str.len() >= 6]
            spot = spot.sort_values("æµé€šå¸‚å€¼").reset_index(drop=True)
            n = min(n, len(spot))
            thirds = np.array_split(spot, 3)
            sizes = [n // 3, n // 3, n - 2 * (n // 3)]
            chosen = []
            for part, k in zip(thirds, sizes):
                if part.empty or k <= 0:
                    continue
                idxs = list(part.index)
                sel = idxs if k >= len(idxs) else random.sample(idxs, k)
                chosen.append(spot.loc[sel])
            uni = pd.concat(chosen, axis=0).drop_duplicates(subset=["ä»£ç "]).reset_index(drop=True)
            out = {}
            for _, row in uni.iterrows():
                code = str(row["ä»£ç "])
                out[code] = {
                    "code": code,
                    "name": str(row["åç§°"]),
                    "mkt_cap": float(row["æµé€šå¸‚å€¼"]) if pd.notna(row["æµé€šå¸‚å€¼"]) else 100e8,
                }
            return out

    info = real_ak.stock_info_a_code_name()
    if info is None or info.empty:
        return {}
    info = info.rename(columns={"code": "ä»£ç ", "name": "åç§°"})
    info = info[~info["åç§°"].str.contains("ST|é€€", na=False)]
    info["ä»£ç "] = info["ä»£ç "].map(_normalize_symbol)
    info = info[info["ä»£ç "].str.len() >= 6].reset_index(drop=True)
    if info.empty:
        return {}
    n = min(n, len(info))
    idxs = list(info.index)
    sel = idxs if n >= len(idxs) else random.sample(idxs, n)
    uni = info.loc[sel].reset_index(drop=True)
    out = {}
    for _, row in uni.iterrows():
        code = str(row["ä»£ç "])
        out[code] = {"code": code, "name": str(row["åç§°"]), "mkt_cap": 100e8}
    return out


def _load_script_from_db(db_path: str, screener_id: int) -> str:
    if not os.path.exists(db_path):
        raise FileNotFoundError(db_path)
    con = sqlite3.connect(db_path)
    try:
        cur = con.cursor()
        cur.execute("SELECT script_content FROM stock_screeners WHERE id = ?", (int(screener_id),))
        row = cur.fetchone()
        if not row or not row[0]:
            raise ValueError(f"stock_screeners.id={screener_id} script_content empty")
        return str(row[0])
    finally:
        con.close()


def _load_script_from_file(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()


def _parse_yyyymmdd(s: str):
    if not s:
        return None
    try:
        return _datetime.datetime.strptime(str(s), "%Y%m%d").date()
    except Exception:
        return None


@dataclass
class BacktestConfig:
    sample_size: int
    seed: int
    test_days: int
    cooldown_days: int
    entry_delay_days: int
    screener_db_id: int
    db_path: str
    v7_file_path: str


class _FixedDateTime(_datetime.datetime):
    _fixed_now = None

    @classmethod
    def now(cls, tz=None):
        if cls._fixed_now is None:
            return super().now(tz=tz)
        if tz is not None:
            return cls._fixed_now.astimezone(tz)
        return cls._fixed_now


class FakeAkshareModule(types.ModuleType):
    def __init__(
        self,
        name: str,
        universe: dict,
        daily_by_code: dict,
        spot_caps: dict,
        current_date: _datetime.date,
        industry_by_code: dict,
    ):
        super().__init__(name)
        self._universe = universe
        self._daily_by_code = daily_by_code
        self._spot_caps = spot_caps
        self._current_date = current_date
        self._industry_by_code = industry_by_code

    def stock_zh_a_spot_em(self):
        rows = []
        for code, meta in self._universe.items():
            daily = self._daily_by_code.get(code)
            if daily is None or daily.empty:
                continue
            mask = daily["date_dt"] == self._current_date
            idxs = daily.index[mask].tolist()
            if not idxs:
                continue
            i = int(idxs[0])
            close = float(daily.loc[i, "æ”¶ç›˜"])
            open_ = float(daily.loc[i, "å¼€ç›˜"])
            high = float(daily.loc[i, "æœ€é«˜"])
            low = float(daily.loc[i, "æœ€ä½"])
            vol = float(daily.loc[i, "æˆäº¤é‡"])
            amt = float(daily.loc[i, "æˆäº¤é¢"])
            prev_close = float(daily.loc[i - 1, "æ”¶ç›˜"]) if i - 1 >= 0 else close
            pct = ((close / prev_close) - 1.0) * 100.0 if prev_close > 0 else 0.0

            vol_hist = daily.loc[max(0, i - 5) : i - 1, "æˆäº¤é‡"]
            vol_mean = float(pd.to_numeric(vol_hist, errors="coerce").mean()) if len(vol_hist) else float("nan")
            vol_ratio = float(vol / vol_mean) if (np.isfinite(vol_mean) and vol_mean > 0) else float("nan")

            cap = float(self._spot_caps.get(code, meta.get("mkt_cap", 100e8)))
            turnover = float((amt / cap) * 100.0) if cap > 0 and np.isfinite(amt) else float("nan")

            rows.append(
                {
                    "ä»£ç ": code,
                    "åç§°": meta.get("name", code),
                    "æœ€æ–°ä»·": close,
                    "æ¶¨è·Œå¹…": pct,
                    "æˆäº¤é‡": vol,
                    "æˆäº¤é¢": amt,
                    "æœ€é«˜": high,
                    "æœ€ä½": low,
                    "ä»Šå¼€": open_,
                    "æ˜¨æ”¶": prev_close,
                    "é‡æ¯”": vol_ratio,
                    "æ¢æ‰‹ç‡": turnover,
                    "æµé€šå¸‚å€¼": cap,
                    "æ€»å¸‚å€¼": cap,
                }
            )

        if not rows:
            return pd.DataFrame()
        return pd.DataFrame(rows)

    def stock_zh_a_hist(self, symbol: str, period="daily", start_date=None, end_date=None, adjust="qfq", **kwargs):
        code = _normalize_symbol(symbol)
        daily = self._daily_by_code.get(code)
        if daily is None or daily.empty:
            return pd.DataFrame()
        sdt = _parse_yyyymmdd(start_date)
        edt = _parse_yyyymmdd(end_date)
        if edt is None:
            edt = self._current_date
        if sdt is None:
            sdt = daily["date_dt"].min()
        out = daily[(daily["date_dt"] >= sdt) & (daily["date_dt"] <= edt)].copy()
        if out.empty:
            return pd.DataFrame()
        keep = ["æ—¥æœŸ", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢", "æŒ¯å¹…", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æ¢æ‰‹ç‡"]
        for c in keep:
            if c not in out.columns:
                out[c] = np.nan
        return out[keep].reset_index(drop=True)

    def stock_individual_info_em(self, symbol: str, timeout=None):
        code = _normalize_symbol(symbol)
        industry = self._industry_by_code.get(code)
        name = self._universe.get(code, {}).get("name", code)
        rows = [
            {"item": "è‚¡ç¥¨ä»£ç ", "value": code},
            {"item": "è‚¡ç¥¨ç®€ç§°", "value": name},
            {"item": "è¡Œä¸š", "value": industry if industry is not None else ""},
        ]
        return pd.DataFrame(rows)

    def stock_sector_fund_flow_rank(self, indicator="5æ—¥", sector_type="è¡Œä¸šèµ„é‡‘æµ", **kwargs):
        if str(indicator) != "5æ—¥" or str(sector_type) != "è¡Œä¸šèµ„é‡‘æµ":
            return pd.DataFrame()

        by_ind = {}
        for code, daily in self._daily_by_code.items():
            ind = self._industry_by_code.get(code)
            if not ind:
                continue
            idxs = daily.index[daily["date_dt"] == self._current_date].tolist()
            if not idxs:
                continue
            i = int(idxs[0])
            start = max(1, i - 4)
            window = daily.loc[start:i].copy()
            close = pd.to_numeric(window["æ”¶ç›˜"], errors="coerce")
            amt = pd.to_numeric(window["æˆäº¤é¢"], errors="coerce")
            rets = close.pct_change().fillna(0.0)
            flow = float(np.nansum(rets.to_numpy(dtype=float) * amt.fillna(0.0).to_numpy(dtype=float)))
            amt_sum = float(np.nansum(amt.fillna(0.0).to_numpy(dtype=float)))
            cur = by_ind.get(ind)
            if cur is None:
                by_ind[ind] = {"flow": flow, "amt": amt_sum}
            else:
                cur["flow"] += flow
                cur["amt"] += amt_sum

        rows = []
        for ind, v in by_ind.items():
            ratio = float((v["flow"] / (v["amt"] + 1e-9)) * 100.0) if v["amt"] > 0 else 0.0
            rows.append({"åç§°": ind, "5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”": ratio})
        if not rows:
            return pd.DataFrame()
        df = pd.DataFrame(rows)
        df["5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”"] = pd.to_numeric(df["5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”"], errors="coerce")
        df = df.sort_values("5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”", ascending=False).reset_index(drop=True)
        df.insert(0, "åºå·", range(1, len(df) + 1))
        return df

    def stock_hot_rank_em(self, **kwargs):
        rows = []
        for code, meta in self._universe.items():
            daily = self._daily_by_code.get(code)
            if daily is None or daily.empty:
                continue
            idxs = daily.index[daily["date_dt"] == self._current_date].tolist()
            if not idxs:
                continue
            i = int(idxs[0])
            amt = float(pd.to_numeric(daily.loc[i, "æˆäº¤é¢"], errors="coerce"))
            close = float(pd.to_numeric(daily.loc[i, "æ”¶ç›˜"], errors="coerce"))
            prev = float(pd.to_numeric(daily.loc[i - 1, "æ”¶ç›˜"], errors="coerce")) if i - 1 >= 0 else close
            pct = ((close / prev) - 1.0) * 100.0 if prev > 0 else 0.0
            rows.append({"ä»£ç ": f"SH{code}", "è‚¡ç¥¨åç§°": meta.get("name", code), "æœ€æ–°ä»·": close, "æ¶¨è·Œå¹…": pct, "_amt": amt})
        if not rows:
            return pd.DataFrame()
        df = pd.DataFrame(rows)
        df["_amt"] = pd.to_numeric(df["_amt"], errors="coerce").fillna(0.0)
        df = df.sort_values("_amt", ascending=False).reset_index(drop=True)
        df.insert(0, "å½“å‰æ’å", range(1, len(df) + 1))
        df["æ¶¨è·Œé¢"] = np.nan
        return df[["å½“å‰æ’å", "ä»£ç ", "è‚¡ç¥¨åç§°", "æœ€æ–°ä»·", "æ¶¨è·Œé¢", "æ¶¨è·Œå¹…"]]

    def stock_js_weibo_report(self, time_period="CNHOUR24", **kwargs):
        if str(time_period) != "CNHOUR24":
            return pd.DataFrame()
        rows = []
        for code, meta in self._universe.items():
            daily = self._daily_by_code.get(code)
            if daily is None or daily.empty:
                continue
            idxs = daily.index[daily["date_dt"] == self._current_date].tolist()
            if not idxs:
                continue
            i = int(idxs[0])
            close = float(pd.to_numeric(daily.loc[i, "æ”¶ç›˜"], errors="coerce"))
            prev = float(pd.to_numeric(daily.loc[i - 1, "æ”¶ç›˜"], errors="coerce")) if i - 1 >= 0 else close
            pct = ((close / prev) - 1.0) * 100.0 if prev > 0 else 0.0
            rows.append({"name": meta.get("name", code), "rate": pct})
        if not rows:
            return pd.DataFrame()
        df = pd.DataFrame(rows)
        df["rate"] = pd.to_numeric(df["rate"], errors="coerce")
        df = df.sort_values("rate", ascending=False).reset_index(drop=True)
        return df

    def tool_trade_date_hist_sina(self):
        today = self._current_date
        dates = pd.date_range(today - _datetime.timedelta(days=3650), today, freq="B").date
        return pd.DataFrame({"trade_date": [str(d) for d in dates]})


def _prepare_daily_history(code: str) -> Optional[pd.DataFrame]:
    df = None
    for _ in range(2):
        try:
            df = real_ak.stock_zh_a_hist(symbol=code, period="daily", adjust="qfq")
            break
        except Exception:
            df = None
            time.sleep(0.5)
    if df is None:
        return None
    if df is None or df.empty:
        return None
    for c in ("å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢"):
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    df = df.dropna(subset=["æ—¥æœŸ", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡"])
    if "æˆäº¤é¢" not in df.columns or df["æˆäº¤é¢"].isna().all():
        df["æˆäº¤é¢"] = df["æ”¶ç›˜"] * df["æˆäº¤é‡"]
    df["date_dt"] = pd.to_datetime(df["æ—¥æœŸ"], errors="coerce").dt.date
    df = df[df["date_dt"].notna()].sort_values("date_dt").reset_index(drop=True)
    return df


def _exec_screener(script: str, fake_ak_mod: types.ModuleType, fixed_dt: _datetime.datetime):
    stdout = io.StringIO()

    old_ak = sys.modules.get("akshare")
    sys.modules["akshare"] = fake_ak_mod

    old_dt_cls = _datetime.datetime
    _FixedDateTime._fixed_now = fixed_dt
    _datetime.datetime = _FixedDateTime

    g = {"__name__": "__main__"}
    try:
        with contextlib.redirect_stdout(stdout):
            exec(script, g, g)
    finally:
        _datetime.datetime = old_dt_cls
        _FixedDateTime._fixed_now = None
        if old_ak is None:
            sys.modules.pop("akshare", None)
        else:
            sys.modules["akshare"] = old_ak

    df = g.get("df")
    if isinstance(df, pd.DataFrame):
        return df.copy()
    if "df_res" in g and isinstance(g["df_res"], pd.DataFrame):
        return g["df_res"].copy()
    if "results" in g and isinstance(g["results"], list):
        try:
            return pd.DataFrame(g["results"])
        except Exception:
            return pd.DataFrame()
    return pd.DataFrame()


def _calc_forward_metrics(daily: pd.DataFrame, entry_date: _datetime.date, entry_px: float):
    out = {"entry": float(entry_px)}
    if daily is None or daily.empty or not np.isfinite(entry_px) or entry_px <= 0:
        return out | {"ret_5": np.nan, "ret_10": np.nan, "ret_20": np.nan, "mae_10": np.nan, "mfe_10": np.nan, "recovery_days_60": None}

    idxs = daily.index[daily["date_dt"] == entry_date].tolist()
    if not idxs:
        return out | {"ret_5": np.nan, "ret_10": np.nan, "ret_20": np.nan, "mae_10": np.nan, "mfe_10": np.nan, "recovery_days_60": None}

    i = int(idxs[0])
    close = daily["æ”¶ç›˜"].to_numpy(dtype=float)
    n = len(close)

    def _ret(h):
        j = i + int(h)
        if j >= n:
            return np.nan
        return float((close[j] - entry_px) / entry_px)

    out["ret_5"] = _ret(5)
    out["ret_10"] = _ret(10)
    out["ret_20"] = _ret(20)

    if i + 10 < n:
        window = close[i : i + 11]
        out["mae_10"] = float((np.nanmin(window) - entry_px) / entry_px)
        out["mfe_10"] = float((np.nanmax(window) - entry_px) / entry_px)
    else:
        out["mae_10"] = np.nan
        out["mfe_10"] = np.nan

    rec = None
    max_days = 60
    for d in range(1, max_days + 1):
        j = i + d
        if j >= n:
            break
        if close[j] >= entry_px:
            rec = d
            break
    out["recovery_days_60"] = rec
    return out


def _analyze(results: List[Dict[str, Any]], title: str):
    if not results:
        return {
            "title": title,
            "count": 0,
            "uniq": 0,
        }
    df = pd.DataFrame(results).replace([np.inf, -np.inf], np.nan)
    uniq = int(df["code"].nunique()) if "code" in df.columns else 0

    def _win_rate(col):
        x = pd.to_numeric(df[col], errors="coerce").dropna()
        if x.empty:
            return np.nan
        return float((x > 0).mean())

    def _mean(col):
        x = pd.to_numeric(df[col], errors="coerce")
        return float(x.mean()) if x.notna().any() else np.nan

    mae = pd.to_numeric(df.get("mae_10"), errors="coerce")
    false_rate = float((mae <= -0.05).mean()) if mae.notna().any() else np.nan
    worst_mae = float(mae.min()) if mae.notna().any() else np.nan
    rec = pd.to_numeric(df.get("recovery_days_60"), errors="coerce")
    rec_ok = float(rec.notna().mean()) if rec is not None and len(rec) else np.nan
    rec_avg = float(rec.mean()) if rec.notna().any() else np.nan

    return {
        "title": title,
        "count": int(len(df)),
        "uniq": uniq,
        "win_5": _win_rate("ret_5"),
        "win_10": _win_rate("ret_10"),
        "win_20": _win_rate("ret_20"),
        "avg_5": _mean("ret_5"),
        "avg_10": _mean("ret_10"),
        "avg_20": _mean("ret_20"),
        "false_10": false_rate,
        "worst_mae_10": worst_mae,
        "rec_ok_60": rec_ok,
        "rec_avg_60": rec_avg,
        "sample": df.sort_values(["date", "code"]).head(10)[["date", "code", "name", "score", "ret_5", "ret_10", "ret_20", "mae_10"]]
        if all(c in df.columns for c in ["date", "code", "name", "score", "ret_5", "ret_10", "ret_20", "mae_10"])
        else None,
    }


def run_backtest(cfg: BacktestConfig):
    universe = _pick_universe(cfg.sample_size, cfg.seed)
    if not universe:
        print("æ ·æœ¬æ± ä¸ºç©ºï¼Œæ— æ³•å›æµ‹")
        return

    spot_caps = {code: meta["mkt_cap"] for code, meta in universe.items()}
    daily_by_code = {}
    for i, code in enumerate(universe.keys(), start=1):
        if i % 20 == 0:
            print(f"â³ æ‹‰å–å†å²: {i}/{len(universe)}")
        daily = _prepare_daily_history(code)
        if daily is None or daily.empty or len(daily) < 320:
            continue
        daily_by_code[code] = daily

    if not daily_by_code:
        print("å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•å›æµ‹")
        return

    industry_by_code = {}
    for i, code in enumerate(daily_by_code.keys(), start=1):
        if i % 40 == 0:
            print(f"â³ æ‹‰å–è¡Œä¸š: {i}/{len(daily_by_code)}")
        industry = None
        for _ in range(2):
            try:
                info_df = real_ak.stock_individual_info_em(symbol=code)
                if info_df is not None and not info_df.empty and "item" in info_df.columns and "value" in info_df.columns:
                    m = info_df["item"].astype(str) == "è¡Œä¸š"
                    if m.any():
                        industry = str(info_df.loc[m, "value"].iloc[0]).strip()
                break
            except Exception:
                time.sleep(0.3)
        if industry:
            industry_by_code[code] = industry

    db_script = _load_script_from_db(cfg.db_path, cfg.screener_db_id)
    v7_script = _load_script_from_file(cfg.v7_file_path)

    trade_df = None
    try:
        trade_df = real_ak.tool_trade_date_hist_sina()
    except Exception:
        trade_df = None
    if trade_df is not None and not trade_df.empty and "trade_date" in trade_df.columns:
        trade_dates = pd.to_datetime(trade_df["trade_date"], errors="coerce").dt.date.dropna().unique().tolist()
        trade_dates = sorted(trade_dates)
    else:
        any_daily = next(iter(daily_by_code.values()))
        trade_dates = sorted(any_daily["date_dt"].unique().tolist())

    today = _datetime.date.today()
    dates = [d for d in trade_dates if d <= today][-int(cfg.test_days) :]
    any_daily = next(iter(daily_by_code.values()))
    available_dates = set(any_daily["date_dt"].tolist())
    dates = [d for d in dates if d in available_dates]

    print("ğŸš€ ä¸¥æ ¼å›æµ‹å¼€å§‹ (ç›´æ¥æ‰§è¡Œè„šæœ¬æ–‡æœ¬)")
    print(f"ğŸ¯ è‚¡ç¥¨æ ·æœ¬: {len(daily_by_code)} åª  seed={cfg.seed}")
    print(f"ğŸ“… å›æµ‹å¤©æ•°: {len(dates)} (ç›®æ ‡ {cfg.test_days})  å†·å´æœŸ={cfg.cooldown_days}å¤©  å…¥åœºå»¶è¿Ÿ={cfg.entry_delay_days}å¤©")
    print(f"ğŸ§© å¯¹æ¯”è„šæœ¬: FILE({os.path.basename(cfg.v7_file_path)}) vs DB(stock_screeners.id={cfg.screener_db_id})")
    print("-" * 70)

    cooldown_a = {}
    cooldown_b = {}
    res_a = []
    res_b = []

    for di, day in enumerate(dates, start=1):
        if di % 20 == 0:
            print(f"â³ è¿›åº¦: {di}/{len(dates)}")
        fixed_dt = _datetime.datetime.combine(day, _datetime.time(hour=15, minute=0, second=0))
        fake = FakeAkshareModule("akshare", universe, daily_by_code, spot_caps, day, industry_by_code)

        df_a = _exec_screener(v7_script, fake, fixed_dt)
        df_b = _exec_screener(db_script, fake, fixed_dt)

        def _ingest(df_out: pd.DataFrame, tag: str):
            if df_out is None or df_out.empty:
                return []
            code_col = "ä»£ç " if "ä»£ç " in df_out.columns else ("ticker" if "ticker" in df_out.columns else None)
            if code_col is None:
                return []
            score_col = "è¯„åˆ†" if "è¯„åˆ†" in df_out.columns else ("score" if "score" in df_out.columns else None)
            out = []
            for _, r in df_out.iterrows():
                code = _normalize_symbol(r.get(code_col))
                if not code or code not in daily_by_code:
                    continue
                if tag == "A":
                    left = cooldown_a.get(code, 0)
                else:
                    left = cooldown_b.get(code, 0)
                if left > 0:
                    continue

                daily = daily_by_code[code]
                idxs = daily.index[daily["date_dt"] == day].tolist()
                if not idxs:
                    continue
                i0 = int(idxs[0])
                entry_i = i0 + int(cfg.entry_delay_days)
                if entry_i >= len(daily):
                    continue
                entry_date = daily.loc[entry_i, "date_dt"]
                entry_px = float(daily.loc[entry_i, "å¼€ç›˜"])
                metrics = _calc_forward_metrics(daily, entry_date, entry_px)
                score = int(r.get(score_col)) if score_col is not None and pd.notna(r.get(score_col)) else None
                out.append(
                    {
                        "date": str(entry_date),
                        "signal_date": str(day),
                        "code": code,
                        "name": universe.get(code, {}).get("name", code),
                        "score": score,
                        **metrics,
                    }
                )
                if tag == "A":
                    cooldown_a[code] = int(cfg.cooldown_days)
                else:
                    cooldown_b[code] = int(cfg.cooldown_days)
            return out

        res_a.extend(_ingest(df_a, "A"))
        res_b.extend(_ingest(df_b, "B"))

        for k in list(cooldown_a.keys()):
            cooldown_a[k] = max(0, int(cooldown_a[k]) - 1)
            if cooldown_a[k] == 0:
                cooldown_a.pop(k, None)
        for k in list(cooldown_b.keys()):
            cooldown_b[k] = max(0, int(cooldown_b[k]) - 1)
            if cooldown_b[k] == 0:
                cooldown_b.pop(k, None)

    a = _analyze(res_a, f"ğŸ”´ æ–‡ä»¶è„šæœ¬({os.path.basename(cfg.v7_file_path)}) ä¸¥æ ¼å›æµ‹")
    b = _analyze(res_b, f"ğŸŸ¢ DBè„šæœ¬(stock_screeners.id={cfg.screener_db_id}) ä¸¥æ ¼å›æµ‹")

    def _print(stat):
        print(f"\n{stat['title']}:")
        print(f"  ä¿¡å·æ€»æ•°: {stat.get('count', 0)}")
        print(f"  è¦†ç›–è‚¡ç¥¨: {stat.get('uniq', 0)}")
        if stat.get("count", 0) <= 0:
            return
        print(f"  5æ—¥èƒœç‡:  {stat['win_5']:.1%}")
        print(f"  10æ—¥èƒœç‡: {stat['win_10']:.1%}")
        print(f"  20æ—¥èƒœç‡: {stat['win_20']:.1%}")
        print(f"  5æ—¥å‡æ”¶:  {stat['avg_5']:.2%}")
        print(f"  10æ—¥å‡æ”¶: {stat['avg_10']:.2%}")
        print(f"  20æ—¥å‡æ”¶: {stat['avg_20']:.2%}")
        print(f"  å‡ä¿¡å·ç‡(10æ—¥è·Œç ´-5%): {stat['false_10']:.1%}")
        print(f"  10æ—¥æœ€å·®å›æ’¤(MAE): {stat['worst_mae_10']:.2%}")
        print(f"  60æ—¥å›æœ¬ç‡: {stat['rec_ok_60']:.1%}")
        print(f"  60æ—¥å¹³å‡å›æœ¬å¤©æ•°: {stat['rec_avg_60']:.1f}")

    print("\n" + "=" * 70)
    print("ğŸ ä¸¥æ ¼å›æµ‹ç»“æœæ±‡æ€»")
    print("=" * 70)
    _print(a)
    _print(b)

    if b.get("sample") is not None and isinstance(b["sample"], pd.DataFrame) and not b["sample"].empty:
        print("\nğŸ” DBè„šæœ¬ä¿¡å·æ ·ä¾‹(å‰10æ¡):")
        print(b["sample"].to_string(index=False))


def main():
    p = argparse.ArgumentParser()
    p.add_argument("--sample-size", type=int, default=120)
    p.add_argument("--seed", type=int, default=7)
    p.add_argument("--test-days", type=int, default=250)
    p.add_argument("--cooldown-days", type=int, default=10)
    p.add_argument("--entry-delay-days", type=int, default=1)
    p.add_argument("--db-path", type=str, default=os.path.join(os.path.dirname(__file__), "..", "stock_watch.db"))
    p.add_argument("--screener-db-id", type=int, default=5)
    p.add_argument(
        "--v7-file-path",
        type=str,
        default=os.path.join(os.path.dirname(__file__), "é€‰è‚¡ç­–ç•¥", "å±±è°·ç‹™å‡»é€‰è‚¡ç­–ç•¥.py"),
    )
    args = p.parse_args()
    cfg = BacktestConfig(
        sample_size=args.sample_size,
        seed=args.seed,
        test_days=args.test_days,
        cooldown_days=args.cooldown_days,
        entry_delay_days=args.entry_delay_days,
        screener_db_id=args.screener_db_id,
        db_path=os.path.abspath(args.db_path),
        v7_file_path=os.path.abspath(args.v7_file_path),
    )
    run_backtest(cfg)


if __name__ == "__main__":
    main()
