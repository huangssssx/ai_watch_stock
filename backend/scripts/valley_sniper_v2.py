# -*- coding: utf-8 -*-
"""
å±±è°·ç‹™å‡»é€‰è‚¡ç­–ç•¥ V2.0 (å®æˆ˜å·¥ç¨‹ç‰ˆ)
Valley Sniper Strategy V2.0 - Production Ready

ã€æ ¸å¿ƒå‡çº§ã€‘
1. Map-Reduce æ¶æ„: ä¸»çº¿ç¨‹å‘é‡åŒ–åˆç­› + çº¿ç¨‹æ± å¹¶å‘å›æµ‹ (è€—æ—¶å‹ç¼© 90%)
2. é²æ£’æ€§å¢å¼º: æŒ‡æ•°é€€é¿é‡è¯• (Retry) + äº¤æ˜“æ—¥å†é”šç‚¹ (Trade Date Anchor)
3. æ•°æ®å·¥ç¨‹: T+0 å‡ ä½•ä¸å˜æ€§æ•°æ®åˆæˆ (Geometric Synthesis)
4. é£æ§å‡çº§: æ¿å—åˆ†å±‚ (BJå‰”é™¤) + åŠ¨æ€ç¯å¢ƒæ»¤ç½‘ (Regime Filter) + å¾®è§‚ç»“æ„ä¿®æ­£ (IBS)

ã€ä½¿ç”¨è¯´æ˜ã€‘
- æœ¬è„šæœ¬ç”±ç³»ç»Ÿè‡ªåŠ¨è°ƒåº¦ï¼Œä¹Ÿå¯åœ¨æœ¬åœ°æ‰‹åŠ¨è¿è¡Œæµ‹è¯•ã€‚
- ä¾èµ–: akshare, pandas, numpy, talib, scipy
"""

import akshare as ak
import pandas as pd
import numpy as np
import talib
import datetime
import time
import random
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import wraps
from scipy.signal import argrelextrema

warnings.filterwarnings("ignore")

# --- é…ç½®å‚æ•° ---
MAX_WORKERS = 8  # å¹¶å‘çº¿ç¨‹æ•°
RETRY_CONFIG = {'max_retries': 3, 'initial_delay': 1.0, 'backoff': 2.0, 'jitter': 0.5}

# åŸºç¡€è¿‡æ»¤å‚æ•°
MIN_TURNOVER = 1.0   # æ¢æ‰‹ç‡ä¸‹é™ %
MAX_TURNOVER = 15.0  # æ¢æ‰‹ç‡ä¸Šé™ %
MAX_PCT_CHG = 9.0    # æ¶¨è·Œå¹…ç»å¯¹å€¼ä¸Šé™ % (é¿å¼€æ¶¨åœ/è·Œåœ/è¿‡çƒ­)
MIN_PRICE = 5.0      # æœ€ä½è‚¡ä»·

# è¯„åˆ†é˜ˆå€¼ (åŠ¨æ€è°ƒæ•´å‰)
THRESHOLD_HIGH_QUALITY = 7
THRESHOLD_POTENTIAL = 4

# ç­–ç•¥å‚æ•°
MA_LONG = 60
MA_SHORT = 20
VWAP_WINDOW = 20
IBS_THRESHOLD = 0.6
VRP_WINDOW = 20

# --- 1. å·¥ç¨‹åº•åº§ (Foundation) ---

def fetch_with_retry(max_retries=3, initial_delay=1.0, backoff=2.0, jitter=0.5):
    """è£…é¥°å™¨ï¼šå¸¦æŒ‡æ•°é€€é¿ä¸æŠ–åŠ¨çš„è‡ªåŠ¨é‡è¯•"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            last_exc = None
            for i in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exc = e
                    if i == max_retries: break
                    sleep_t = delay * (1 + random.uniform(-jitter, jitter))
                    time.sleep(max(0.1, sleep_t))
                    delay *= backoff
            print(f"âŒ [Retry] å‡½æ•° {func.__name__} å¤±è´¥: {last_exc}")
            raise last_exc
        return wrapper
    return decorator

@fetch_with_retry(**RETRY_CONFIG)
def get_trade_date_anchor():
    """è·å–æœ€è¿‘çš„ä¸€ä¸ªäº¤æ˜“æ—¥ä½œä¸ºå…¨å±€æ—¶é—´é”šç‚¹"""
    try:
        # å°è¯•è·å–äº¤æ˜“æ—¥å†
        tool_trade_date_hist_sina_df = ak.tool_trade_date_hist_sina()
        recent_dates = pd.to_datetime(tool_trade_date_hist_sina_df['trade_date']).dt.date
        today = datetime.date.today()
        # æ‰¾åˆ°ä»Šå¤©æˆ–ä»Šå¤©ä¹‹å‰çš„æœ€è¿‘äº¤æ˜“æ—¥
        trade_date = recent_dates[recent_dates <= today].iloc[-1]
        return trade_date.strftime("%Y-%m-%d")
    except Exception:
        # é™çº§æ–¹æ¡ˆï¼šå¦‚æœæ˜¯å‘¨å…­æ—¥ï¼Œæ¨åˆ°å‘¨äº”
        today = datetime.date.today()
        if today.weekday() == 5: # Sat
            return (today - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
        elif today.weekday() == 6: # Sun
            return (today - datetime.timedelta(days=2)).strftime("%Y-%m-%d")
        return today.strftime("%Y-%m-%d")

def synthesize_realtime_data(hist_df: pd.DataFrame, spot_row: pd.Series, trade_date: str) -> pd.DataFrame:
    """
    T+0 æ•°æ®åˆæˆ (æ ¸å¿ƒç®—æ³•)
    åˆ©ç”¨æ¶¨è·Œå¹…æ¯”ç‡çš„å‡ ä½•ä¸å˜æ€§ï¼Œå°† Snapshot æ‹¼æ¥åˆ° History
    """
    if hist_df.empty: return hist_df
    
    # 1. æ—¥æœŸé˜²é‡æ£€æŸ¥
    try:
        last_hist_date = pd.to_datetime(hist_df.iloc[-1]['æ—¥æœŸ']).strftime("%Y-%m-%d")
    except:
        last_hist_date = "1970-01-01"
        
    if last_hist_date >= trade_date:
        # å†å²æ•°æ®å·²åŒ…å«ä»Šæ—¥ï¼Œæˆ–ä»Šæ—¥éäº¤æ˜“æ—¥
        return hist_df

    # 2. å‡ ä½•åˆæˆ
    last_adj_close = float(hist_df.iloc[-1]["æ”¶ç›˜"])
    
    spot_pre = float(spot_row.get("æ˜¨æ”¶", 0))
    if spot_pre == 0: return hist_df # å¼‚å¸¸æ•°æ®
    
    # è®¡ç®—æ¯”ç‡ (Ratios)
    r_open = float(spot_row.get("å¼€ç›˜", 0)) / spot_pre
    r_close = float(spot_row.get("æœ€æ–°ä»·", 0)) / spot_pre
    r_high = float(spot_row.get("æœ€é«˜", 0)) / spot_pre
    r_low = float(spot_row.get("æœ€ä½", 0)) / spot_pre
    
    # æ¨å¯¼ä»Šæ—¥å¤æƒä»·
    new_row = {
        "æ—¥æœŸ": trade_date,
        "å¼€ç›˜": last_adj_close * r_open,
        "æ”¶ç›˜": last_adj_close * r_close,
        "æœ€é«˜": last_adj_close * r_high,
        "æœ€ä½": last_adj_close * r_low,
        "æˆäº¤é‡": float(spot_row.get("æˆäº¤é‡", 0)),
        "æˆäº¤é¢": float(spot_row.get("æˆäº¤é¢", 0)),
        "æ¢æ‰‹ç‡": float(spot_row.get("æ¢æ‰‹ç‡", 0))
    }
    
    # 3. æ‹¼æ¥
    return pd.concat([hist_df, pd.DataFrame([new_row])], ignore_index=True)

# --- 2. ç­–ç•¥é€»è¾‘ (Logic) ---

def _kalman_filter_1d(values: pd.Series, q=1e-5, r_scale=0.20):
    """Kalman é™å™ª"""
    v = values.values
    if len(v) == 0: return values
    x = v[0]
    p = 1.0
    out = np.empty_like(v)
    for i in range(len(v)):
        p += q
        k = p / (p + r_scale)
        x += k * (v[i] - x)
        p *= (1 - k)
        out[i] = x
    return pd.Series(out, index=values.index)

def calculate_ibs(close, high, low):
    """Internal Bar Strength"""
    rng = high - low
    if rng == 0: return 0.5 # è¾¹ç•Œä¿æŠ¤ï¼šä¸€å­—æ¿/åœç‰Œè§†ä¸ºä¸­æ€§
    return (close - low) / rng

def check_market_regime():
    """å¤§ç›˜ç¯å¢ƒæ»¤ç½‘"""
    try:
        # è·å–ä¸Šè¯æŒ‡æ•°
        idx_df = ak.stock_zh_index_daily(symbol="sh000001")
        if idx_df.empty: return 0
        
        close = idx_df['close']
        ma20 = close.rolling(20).mean()
        ma60 = close.rolling(60).mean()
        
        curr_p = close.iloc[-1]
        curr_ma20 = ma20.iloc[-1]
        curr_ma60 = ma60.iloc[-1]
        
        penalty = 0
        if curr_p < curr_ma20:
            penalty += 1 # é»„ç¯
        if curr_p < curr_ma60:
            penalty += 1 # çº¢ç¯ (ç´¯ç§¯+2)
            
        return penalty
    except:
        return 0 # è·å–å¤±è´¥é»˜è®¤æ­£å¸¸

def process_single_stock(code, name, spot_row, trade_date, threshold_adj):
    """
    Reduce é˜¶æ®µï¼šå•åªè‚¡ç¥¨æ·±åº¦åˆ†æ
    """
    try:
        # 1. æ‹‰å–å†å²æ•°æ® (QFQ)
        df_hist = ak.stock_zh_a_hist(symbol=code, period="daily", adjust="qfq")
        if df_hist is None or df_hist.empty or len(df_hist) < 250: # æ¬¡æ–°è‚¡è¿‡æ»¤
            return None
            
        # 2. T+0 æ•°æ®åˆæˆ
        df = synthesize_realtime_data(df_hist, spot_row, trade_date)
        if len(df) < 250: return None
        
        # 3. å‡†å¤‡æ•°æ®åºåˆ—
        close = df["æ”¶ç›˜"]
        high = df["æœ€é«˜"]
        low = df["æœ€ä½"]
        vol = df["æˆäº¤é‡"]
        
        curr_price = close.iloc[-1]
        
        score = 0
        signals = []
        
        # --- A. æˆæœ¬ä¸è¶‹åŠ¿ (Cost & Trend) ---
        ma60 = close.rolling(60).mean()
        # VWAP 20 (ç®€æ˜“è®¡ç®—: Amount/Vol è¿‘ä¼¼ä¸º Close*Vol/Vol = Close çš„åŠ æƒ)
        # å‡†ç¡® VWAP éœ€è¦ Amount, è¿™é‡Œç”¨å…¸å‹ä»·æ ¼è¿‘ä¼¼
        typ_price = (high + low + close) / 3
        vwap20 = (typ_price * vol).rolling(20).sum() / vol.rolling(20).sum()
        
        curr_ma60 = ma60.iloc[-1]
        curr_vwap = vwap20.iloc[-1]
        prev_vwap = vwap20.iloc[-2]
        
        # æˆæœ¬æ”¯æ’‘é€»è¾‘: å¿…é¡»åœ¨ VWAP ä¹‹ä¸Š æˆ– VWAP æ‹å¤´å‘ä¸Š
        cost_support = (curr_price > curr_vwap) or (curr_vwap > prev_vwap)
        
        # BIAS ä¿æŠ¤: å¦‚æœç¦» MA60 å¤ªè¿œ (æ·±è·Œ), å¿…é¡»æœ‰å¼ºåŠ›åº•èƒŒç¦»æ‰è¡Œ
        bias60 = (curr_price - curr_ma60) / curr_ma60
        is_deep_fall = bias60 < -0.20
        
        if not cost_support:
            return None # è¿çŸ­æœŸæˆæœ¬éƒ½ç«™ä¸ç¨³ï¼Œç›´æ¥æ”¾å¼ƒ
            
        # --- B. ç­–ç•¥æ‰“åˆ† (Scoring) ---
        
        # 1. ç¼©é‡ (Volume)
        vol5_med = vol.iloc[-5:].median()
        vol120_quantile = vol.iloc[-120:].rank(pct=True).iloc[-1] # å½“å‰é‡åœ¨120å¤©åˆ†ä½
        
        # åŠ¨æ€ç¼©é‡åˆ†: å¸‚å€¼è¶Šå¤§è¦æ±‚è¶Šæ¾ (æ­¤å¤„ç®€åŒ–ï¼Œç»Ÿä¸€é€»è¾‘)
        if vol.iloc[-1] < vol.rolling(20).mean().iloc[-1]: # ä»Šæ—¥ç¼©é‡
            if vol120_quantile < 0.15:
                score += 3
                signals.append(f"æç¼©é‡({int(vol120_quantile*100)}%)")
            elif vol120_quantile < 0.25:
                score += 1
                signals.append("ç¼©é‡")
                
        # 2. VRP (ææ…Œæº¢ä»·)
        ret = close.pct_change()
        rv = ret.rolling(5).std()
        iv_proxy = ret.rolling(VRP_WINDOW).std()
        vrp = iv_proxy - rv
        # VRP åˆ†ä½
        vrp_rank = vrp.rolling(120).rank(pct=True).iloc[-1]
        if vrp_rank > 0.8:
            score += 2
            signals.append("VRPææ…Œ")
            
        # 3. Kalman MACD/RSI (èƒŒç¦»)
        smooth_c = _kalman_filter_1d(close)
        
        # MACD
        dif, dea, macd_bar = talib.MACD(smooth_c.values)
        # ç®€å•åº•èƒŒç¦»æ£€æµ‹: ä»·æ ¼æ–°ä½(è¿‘20å¤©) ä½† MACD æœªæ–°ä½
        low_20 = close.rolling(20).min().iloc[-1]
        macd_low_20 = pd.Series(dif).rolling(20).min().iloc[-1]
        
        if close.iloc[-1] <= low_20 * 1.02 and dif[-1] > macd_low_20:
             # äºŒæ¬¡ç¡®è®¤: é‡‘å‰æˆ–å³å°†é‡‘å‰
             if macd_bar[-1] > macd_bar[-2]:
                 score += 3
                 signals.append("MACDèƒŒç¦»")
        
        # RSI
        rsi = talib.RSI(smooth_c.values, timeperiod=14)
        if rsi[-1] < 30:
            score += 1
            signals.append("RSIè¶…å–")
        elif rsi[-1] < 45 and rsi[-1] > rsi[-2]: # ä½ä½å›å‡
            score += 1
            
        # 4. å¾®è§‚ç»“æ„ IBS (èµ„é‡‘æ‰¿æ¥)
        ibs = calculate_ibs(close.iloc[-1], high.iloc[-1], low.iloc[-1])
        ma5_vol = vol.rolling(5).mean().iloc[-1]
        if ibs > 0.6 and vol.iloc[-1] > ma5_vol:
            score += 2
            signals.append("èµ„é‡‘æ‰¿æ¥")
            
        # 5. MA60 å¥–åŠ± (å³ä¾§ç¡®è®¤)
        if curr_price > curr_ma60:
            score += 1
            signals.append("ç«™ä¸Šç”Ÿå‘½çº¿")
            
        # 6. æ·±è·Œä¿æŠ¤é€»è¾‘æ ¡éªŒ
        if is_deep_fall:
            # æ·±è·Œæ—¶ï¼Œå¿…é¡»æœ‰ MACD èƒŒç¦» æˆ– VRP ææ…Œ æ‰èƒ½å…¥é€‰
            if not ("MACDèƒŒç¦»" in signals or "VRPææ…Œ" in signals):
                return None

        # --- C. ç»“æœç»„è£… ---
        final_threshold = THRESHOLD_POTENTIAL + threshold_adj
        
        if score >= final_threshold:
            return {
                "ä»£ç ": code,
                "åç§°": name,
                "ç°ä»·": float(spot_row["æœ€æ–°ä»·"]),
                "æ¶¨è·Œ%": float(spot_row["æ¶¨è·Œå¹…"]),
                "è¯„åˆ†": score,
                "IBS": round(ibs, 2),
                "VRPåˆ†ä½": round(vrp_rank, 2),
                "ç¼©é‡åˆ†ä½": round(vol120_quantile, 2),
                "BIAS60": round(bias60, 2),
                "ä¿¡å·": "+".join(signals)
            }
            
    except Exception as e:
        # print(f"Error processing {code}: {e}")
        return None
    return None

# --- 3. Map é˜¶æ®µ (Map) ---

@fetch_with_retry(**RETRY_CONFIG)
def get_candidates():
    """å…¨å¸‚åœºå¿«ç…§ä¸å‘é‡åŒ–åˆç­›"""
    print("ğŸ“¡ Mapé˜¶æ®µ: è·å–å…¨å¸‚åœºå¿«ç…§...")
    df = ak.stock_zh_a_spot_em()
    
    total = len(df)
    
    # 1. æ¿å—è¿‡æ»¤ (å‰”é™¤ BJ/8/4/9)
    # å…¼å®¹: ä»£ç åˆ—å¯èƒ½å« 'ä»£ç ' æˆ– 'code'
    code_col = 'ä»£ç ' if 'ä»£ç ' in df.columns else 'code'
    df[code_col] = df[code_col].astype(str)
    
    mask_bj = df[code_col].str.match(r'^(8|4|9|bj)')
    df = df[~mask_bj]
    
    # 2. ST è¿‡æ»¤
    name_col = 'åç§°' if 'åç§°' in df.columns else 'name'
    mask_st = df[name_col].str.contains('ST|é€€', na=False)
    df = df[~mask_st]
    
    # 3. æµåŠ¨æ€§ä¸ä»·æ ¼è¿‡æ»¤
    # ç¡®ä¿æ•°å€¼åˆ—ä¸º float
    num_cols = ['æœ€æ–°ä»·', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æœ€é«˜', 'æœ€ä½', 'å¼€ç›˜', 'æ˜¨æ”¶']
    for col in num_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            
    mask_valid = (
        (df['æ¢æ‰‹ç‡'] > MIN_TURNOVER) & 
        (df['æ¢æ‰‹ç‡'] < MAX_TURNOVER) & 
        (df['æœ€æ–°ä»·'] >= MIN_PRICE) & 
        (df['æ¶¨è·Œå¹…'].abs() < MAX_PCT_CHG)
    )
    df = df[mask_valid]
    
    print(f"ğŸ§¹ æ¸…æ´—å®Œæˆ: {total} -> {len(df)} (å‰”é™¤åŒ—äº¤æ‰€/ST/åƒµå°¸è‚¡/æ¶¨åœè‚¡)")
    return df

# --- ä¸»ç¨‹åº ---

def main():
    print(f"ğŸš€ å±±è°·ç‹™å‡» V2.0 å¯åŠ¨ | çº¿ç¨‹æ•°: {MAX_WORKERS}")
    
    # 1. è·å–æ—¶é—´é”šç‚¹
    trade_date = get_trade_date_anchor()
    print(f"ğŸ“… äº¤æ˜“æ—¥é”šç‚¹: {trade_date}")
    
    # 2. æ£€æŸ¥å¤§ç›˜ç¯å¢ƒ (Regime)
    threshold_adj = check_market_regime()
    regime_msg = ["ç»¿ç¯ (æ­£å¸¸)", "é»„ç¯ (å›è°ƒ +1)", "çº¢ç¯ (æ·±è·Œ +2)"][min(threshold_adj, 2)]
    print(f"ğŸŒ¡ï¸ å¸‚åœºç¯å¢ƒ: {regime_msg}")
    
    # 3. Map
    candidates = get_candidates()
    if candidates.empty:
        print("âš ï¸ å€™é€‰æ± ä¸ºç©ºï¼Œç»“æŸè¿è¡Œã€‚")
        return pd.DataFrame(), []

    # 4. Reduce
    results = []
    print(f"âš¡ Reduceé˜¶æ®µ: å¹¶å‘å›æµ‹ {len(candidates)} åªæ ‡çš„...")
    
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = []
        for _, row in candidates.iterrows():
            futures.append(
                executor.submit(
                    process_single_stock, 
                    row['ä»£ç '], row['åç§°'], row, trade_date, threshold_adj
                )
            )
        
        # è¿›åº¦æ¡
        count = 0
        total = len(futures)
        for future in as_completed(futures):
            res = future.result()
            if res:
                results.append(res)
            count += 1
            if count % 50 == 0:
                print(f"è¿›åº¦: {count}/{total}...")
                
    elapsed = time.time() - start_time
    print(f"\nâœ… è¿è¡Œè€—æ—¶: {elapsed:.1f}s | å‘½ä¸­: {len(results)} åª")
    
    # 5. è¾“å‡º
    df_res = pd.DataFrame(results)
    if not df_res.empty:
        df_res = df_res.sort_values(by="è¯„åˆ†", ascending=False)
        
        print("\n" + "="*50)
        print(f"ğŸŒŸ ã€ä¸¥é€‰æ¦œã€‘ (è¯„åˆ†>={THRESHOLD_HIGH_QUALITY + threshold_adj})")
        print("="*50)
        high_q = df_res[df_res["è¯„åˆ†"] >= (THRESHOLD_HIGH_QUALITY + threshold_adj)]
        print(high_q.to_string(index=False) if not high_q.empty else "æš‚æ— ")
        
        print("\n" + "-"*50)
        print(f"ğŸ‘€ ã€æ½œåŠ›æ¦œã€‘ (è¯„åˆ†>={THRESHOLD_POTENTIAL + threshold_adj})")
        print("-"*50)
        pot = df_res[(df_res["è¯„åˆ†"] >= (THRESHOLD_POTENTIAL + threshold_adj)) & 
                     (df_res["è¯„åˆ†"] < (THRESHOLD_HIGH_QUALITY + threshold_adj))]
        print(pot.head(50).to_string(index=False) if not pot.empty else "æš‚æ— ")
        
        return df_res, results
    else:
        print("æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        return pd.DataFrame(), []

df, result = main()
