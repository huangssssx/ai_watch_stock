import os
import sys
try:
    getattr(sys.stderr, 'flush', lambda: None)()
except Exception:
    try:
        sys.stderr = open(os.devnull, 'w')
    except Exception:
        pass
os.environ.setdefault('TQDM_DISABLE', '1')
_backend_dir = os.path.dirname(os.path.abspath(__file__))
if _backend_dir not in sys.path:
    sys.path.insert(0, _backend_dir)
from pymr_compat import ensure_py_mini_racer
ensure_py_mini_racer()

import streamlit as st
import os
import sys
import akshare as ak
import pandas as pd
import json
import datetime
import time
import traceback

try:
    sys.stderr = open(os.devnull, "w")
except Exception:
    pass

# --- Configuration ---
st.set_page_config(page_title="å¤§ç›˜å…¨æ™¯çœ‹æ¿", layout="wide")

# --- Styles ---
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
    }
    .metric-value {
        font-size: 24px;
        font-weight: bold;
    }
    .metric-delta {
        font-size: 14px;
    }
    .stButton>button {
        width: 100%;
    }
</style>
""", unsafe_allow_html=True)

# --- Data Fetching (Cached) ---
@st.cache_data(ttl=60)
def load_market_data(run_token: str):
    data = {}
    logs = []

    def _try_call(label: str, fn, retries: int = 2, sleep_s: float = 0.6):
        last_err = None
        for i in range(retries + 1):
            t0 = time.time()
            try:
                v = fn()
                dt = time.time() - t0
                logs.append(f"[OK] {label} {dt:.2f}s")
                return v
            except Exception as e:
                dt = time.time() - t0
                last_err = e
                logs.append(f"[ERR] {label} {dt:.2f}s {repr(e)}")
                logs.append(traceback.format_exc())
                if i < retries:
                    time.sleep(sleep_s)
        raise last_err

    # 1. Indices (Sina is fast and stable)
    try:
        df_index = _try_call("stock_zh_index_spot_sina", lambda: ak.stock_zh_index_spot_sina())
        # Filter Key Indices
        targets = ["ä¸Šè¯æŒ‡æ•°", "æ·±è¯æˆæŒ‡", "åˆ›ä¸šæ¿æŒ‡", "ç§‘åˆ›50"] 
        # Note: Sina names might vary slightly, e.g. "ä¸Šè¯æŒ‡æ•°"
        if isinstance(df_index, pd.DataFrame) and (not df_index.empty) and ("åç§°" in df_index.columns):
            data['indices'] = df_index[df_index['åç§°'].isin(targets)].copy()
        else:
            data['indices'] = pd.DataFrame()
    except Exception as e:
        st.error(f"æŒ‡æ•°æ•°æ®è·å–å¤±è´¥: {e}")
        data['indices'] = pd.DataFrame()

    # 2. Northbound Funds
    try:
        df_north = _try_call("stock_hsgt_fund_flow_summary_em", lambda: ak.stock_hsgt_fund_flow_summary_em())
        if isinstance(df_north, pd.DataFrame):
            data['hsgt'] = df_north.copy()
        else:
            data['hsgt'] = pd.DataFrame()
        # Usually row 0 is Northbound (æ²ªè‚¡é€š+æ·±è‚¡é€š sum is not directly given, need to sum)
        # Structure: æ²ªè‚¡é€š(North), æ¸¯è‚¡é€š(South), æ·±è‚¡é€š(North), æ¸¯è‚¡é€š(South)
        # We need rows where "èµ„é‡‘æ–¹å‘" == "åŒ—å‘"
        if not df_north.empty and 'èµ„é‡‘æ–¹å‘' in df_north.columns:
            data['north'] = df_north[df_north['èµ„é‡‘æ–¹å‘'] == 'åŒ—å‘'].copy()
            data['south'] = df_north[df_north['èµ„é‡‘æ–¹å‘'] == 'å—å‘'].copy()
        else:
            data['north'] = pd.DataFrame()
            data['south'] = pd.DataFrame()
    except Exception as e:
        # Fallback
        data['hsgt'] = pd.DataFrame()
        data['north'] = pd.DataFrame()
        data['south'] = pd.DataFrame()

    # 3. Market Summary (Breadth)
    try:
        sse = _try_call("stock_sse_summary", lambda: ak.stock_sse_summary())
        szse = _try_call("stock_szse_summary", lambda: ak.stock_szse_summary())
        data['sse'] = sse
        data['szse'] = szse
    except:
        pass

    # 4. Sectors
    try:
        sectors = _try_call("stock_board_industry_name_em", lambda: ak.stock_board_industry_name_em())
        data['sectors'] = sectors
    except:
        data['sectors'] = pd.DataFrame()

    data["_logs"] = "\n".join(logs[-120:])
    return data

# --- UI Layout ---

col_header_1, col_header_2 = st.columns([3, 1])
with col_header_1:
    st.title("ğŸ“Š Aè‚¡å¤§ç›˜å…¨æ™¯ç›‘æµ‹")
    st.caption(f"æœ€åæ›´æ–°: {datetime.datetime.now().strftime('%H:%M:%S')}")

with col_header_2:
    if st.button("ğŸ”„ ç«‹å³åˆ·æ–°æ•°æ®"):
        st.session_state["_market_run_token"] = str(time.time())
        st.rerun()

if "_market_run_token" not in st.session_state:
    st.session_state["_market_run_token"] = str(time.time())

if "_market_first_enter_done" not in st.session_state:
    st.session_state["_market_first_enter_done"] = True
    st.session_state["_market_run_token"] = str(time.time())

# Load Data
with st.spinner("æ­£åœ¨è¿æ¥è¡Œæƒ…ä¸­å¿ƒ..."):
    market_data = load_market_data(st.session_state["_market_run_token"])

with st.expander("è¿è¡Œæ—¥å¿—", expanded=False):
    st.code(market_data.get("_logs", ""), language="text")

with st.expander("å¯¼å‡ºæ•°æ®(JSON)", expanded=False):
    indices_df_export = market_data.get("indices", pd.DataFrame())
    hsgt_df_export = market_data.get("hsgt", pd.DataFrame())
    sectors_df_export = market_data.get("sectors", pd.DataFrame())

    include_full_sectors = st.checkbox("åŒ…å«å…¨é‡è¡Œä¸šåˆ—è¡¨", value=False)
    export_payload = {
        "generated_at": datetime.datetime.now().isoformat(timespec="seconds"),
        "indices": indices_df_export.to_dict(orient="records") if isinstance(indices_df_export, pd.DataFrame) else [],
        "fund_flow": hsgt_df_export.to_dict(orient="records") if isinstance(hsgt_df_export, pd.DataFrame) else [],
        "sectors_top10": [],
        "sectors_bottom10": [],
        "sectors": [],
    }

    if isinstance(sectors_df_export, pd.DataFrame) and (not sectors_df_export.empty) and ("æ¶¨è·Œå¹…" in sectors_df_export.columns):
        top_10_export = sectors_df_export.sort_values(by="æ¶¨è·Œå¹…", ascending=False).head(10)
        bottom_10_export = sectors_df_export.sort_values(by="æ¶¨è·Œå¹…", ascending=True).head(10)
        export_payload["sectors_top10"] = top_10_export.to_dict(orient="records")
        export_payload["sectors_bottom10"] = bottom_10_export.to_dict(orient="records")
        if include_full_sectors:
            export_payload["sectors"] = sectors_df_export.to_dict(orient="records")

    export_json = json.dumps(export_payload, ensure_ascii=False, indent=2, default=str)
    st.download_button(
        "â¬‡ï¸ å¯¼å‡º JSON",
        data=export_json,
        file_name=f"market_dashboard_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json",
        use_container_width=True,
    )
    st.code(export_json, language="json")

# --- Section 1: Key Indices ---
st.subheader("æ ¸å¿ƒæŒ‡æ•°")
cols = st.columns(4)
indices_df = market_data.get('indices', pd.DataFrame())

if not indices_df.empty:
    # Sort to ensure order if possible, or just iterate
    # Target order: SH, SZ, CYB, KC50
    target_order = ["ä¸Šè¯æŒ‡æ•°", "æ·±è¯æˆæŒ‡", "åˆ›ä¸šæ¿æŒ‡", "ç§‘åˆ›50"]
    
    for i, name in enumerate(target_order):
        row = indices_df[indices_df['åç§°'] == name]
        if not row.empty:
            price = pd.to_numeric(row.iloc[0]['æœ€æ–°ä»·'], errors='coerce')
            change = pd.to_numeric(row.iloc[0]['æ¶¨è·Œå¹…'], errors='coerce')
            with cols[i]:
                st.metric(label=name, value=f"{price:.2f}" if pd.notna(price) else "-", delta=f"{change:.2f}%" if pd.notna(change) else None)
else:
    st.warning("æš‚æ— æŒ‡æ•°æ•°æ®")

st.divider()

# --- Section 2: Market Sentiment & Funds ---
col_fund, col_breadth = st.columns([1, 2])

with col_fund:
    st.subheader("ğŸ’¸ èµ„é‡‘é£å‘")
    hsgt_df = market_data.get('hsgt', pd.DataFrame())
    if not hsgt_df.empty:
        direction = st.segmented_control(
            "èµ„é‡‘æ–¹å‘",
            options=["åŒ—å‘", "å—å‘", "å…¨éƒ¨"],
            default="åŒ—å‘",
            label_visibility="collapsed",
        )
        if direction == "åŒ—å‘":
            df_flow = hsgt_df[hsgt_df.get('èµ„é‡‘æ–¹å‘', '') == 'åŒ—å‘'].copy()
        elif direction == "å—å‘":
            df_flow = hsgt_df[hsgt_df.get('èµ„é‡‘æ–¹å‘', '') == 'å—å‘'].copy()
        else:
            df_flow = hsgt_df.copy()

        total_in = float("nan")
        total_buy = float("nan")
        try:
            if 'èµ„é‡‘å‡€æµå…¥' in df_flow.columns:
                total_in = pd.to_numeric(df_flow['èµ„é‡‘å‡€æµå…¥'], errors='coerce').sum(min_count=1)
            if 'æˆäº¤å‡€ä¹°é¢' in df_flow.columns:
                total_buy = pd.to_numeric(df_flow['æˆäº¤å‡€ä¹°é¢'], errors='coerce').sum(min_count=1)
        except:
            pass

        status_hint = ""
        try:
            if 'äº¤æ˜“çŠ¶æ€' in df_flow.columns:
                status_vals = [str(x) for x in pd.unique(df_flow['äº¤æ˜“çŠ¶æ€'].dropna()).tolist()]
                if status_vals:
                    status_hint = f"äº¤æ˜“çŠ¶æ€: {', '.join(status_vals)}"
        except:
            pass

        if pd.isna(total_buy) and pd.isna(total_in):
            st.info("èµ„é‡‘æ¥å£è¿”å›ä¸ºç©ºæˆ–å­—æ®µæ— æ³•è§£æ")
        elif pd.notna(total_buy):
            st.metric(
                f"{direction}æˆäº¤å‡€ä¹°é¢(åˆè®¡)",
                f"{total_buy:.2f}",
                delta="æµå…¥" if total_buy > 0 else "æµå‡º"
            )
        elif pd.notna(total_in):
            st.metric(
                f"{direction}èµ„é‡‘å‡€æµå…¥(åˆè®¡)",
                f"{total_in:.2f}",
                delta="æµå…¥" if total_in > 0 else "æµå‡º"
            )

        if direction == "åŒ—å‘" and (pd.notna(total_buy) and abs(float(total_buy)) < 1e-9) and status_hint:
            st.caption(f"æç¤ºï¼šå½“å‰åŒ—å‘æ•°æ®ä¸º 0ï¼Œ{status_hint}ï¼ˆå¯èƒ½ä¼‘å¸‚/ä¸Šæ¸¸æš‚æ— æ•°æ®ï¼‰")
        elif status_hint:
            st.caption(status_hint)

        show_cols = [c for c in ['äº¤æ˜“æ—¥', 'æ¿å—', 'èµ„é‡‘æ–¹å‘', 'äº¤æ˜“çŠ¶æ€', 'èµ„é‡‘å‡€æµå…¥', 'æˆäº¤å‡€ä¹°é¢', 'å½“æ—¥èµ„é‡‘ä½™é¢'] if c in df_flow.columns]
        if show_cols:
            st.dataframe(df_flow[show_cols], hide_index=True)
        else:
            st.dataframe(df_flow, hide_index=True)
    else:
        st.info("èµ„é‡‘æ•°æ®ä¸å¯ç”¨")

with col_breadth:
    st.subheader("ğŸŒ¡ï¸ å¸‚åœºæ¸©åº¦")
    # Calculate approximate Up/Down from Summary if available, or just verify
    # SSE Summary has 'ä¸Šå¸‚è‚¡ç¥¨' but not Up/Down count directly. 
    # SZSE Summary also general.
    # To get exact Up/Down, we need a snapshot or estimate.
    # Let's use Sectors as a proxy for heat.
    
    sectors = market_data.get('sectors', pd.DataFrame())
    if not sectors.empty:
        up_sectors = len(sectors[sectors['æ¶¨è·Œå¹…'] > 0])
        down_sectors = len(sectors[sectors['æ¶¨è·Œå¹…'] < 0])
        total_sectors = len(sectors)
        
        st.write(f"è¡Œä¸šæ¿å—æ¶¨è·Œåˆ†å¸ƒ: ğŸŸ¥ {up_sectors} æ¶¨ / ğŸŸ© {down_sectors} è·Œ")
        
        # Simple progress bar for sentiment
        sentiment_score = up_sectors / total_sectors if total_sectors > 0 else 0.5
        st.progress(sentiment_score, text=f"å¸‚åœºæƒ…ç»ª (è¡Œä¸šç»´åº¦): {int(sentiment_score*100)}%")
    else:
        st.info("æ¿å—æ•°æ®ä¸å¯ç”¨")

st.divider()

# --- Section 3: Sector Performance ---
st.subheader("ğŸš€ è¡Œä¸šçƒ­åº¦æ¦œ")

sectors = market_data.get('sectors', pd.DataFrame())
if not sectors.empty:
    # Top 10 Gainers
    top_10 = sectors.sort_values(by="æ¶¨è·Œå¹…", ascending=False).head(10)
    # Bottom 10 Losers
    bottom_10 = sectors.sort_values(by="æ¶¨è·Œå¹…", ascending=True).head(10)
    
    col_top, col_bottom = st.columns(2)
    
    with col_top:
        st.markdown("**æ¶¨å¹… Top 10**")
        df_up = top_10[['æ¿å—åç§°', 'æ¶¨è·Œå¹…']].set_index('æ¿å—åç§°')
        st.bar_chart(df_up, height=380)
        
    with col_bottom:
        st.markdown("**è·Œå¹… Top 10**")
        df_down = bottom_10[['æ¿å—åç§°', 'æ¶¨è·Œå¹…']].set_index('æ¿å—åç§°')
        st.bar_chart(df_down, height=380)
else:
    st.error("æ— æ³•åŠ è½½è¡Œä¸šæ•°æ®")

